{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to L'Atelier des Chefs: du monolith aux micro-services Homics -> Hands On Micro Service Subject Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices. Presentation Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github . What does microservice mean? Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey? Why microservice? It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Home"},{"location":"#welcome-to-latelier-des-chefs-du-monolith-aux-micro-services","text":"Homics -> Hands On Micro Service","title":"Welcome to L'Atelier des Chefs: du monolith aux micro-services"},{"location":"#subject","text":"Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices.","title":"Subject"},{"location":"#presentation","text":"Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github .","title":"Presentation"},{"location":"#what-does-microservice-mean","text":"Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey?","title":"What does microservice mean?"},{"location":"#why-microservice","text":"It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Why microservice?"},{"location":"about/","text":"About us Speakers Nicolas Favier Eric Ndouakulu Kiaku Mbuta Benjamin Yvernault Benjamin recently left the world of data for the applications Web univers. He joined Takima beginning 2018. Takima is a consulting company specialised in fullstack development, DevOps, or Big Data. Since October 2018, he works at Mirakl, the leading provider of Marketplace Solutions. He joined one of the team developing the core system of the monolith. Takima & Mirakl at the Paris DevoxX 2019: Come see us in person","title":"About"},{"location":"about/#about-us","text":"","title":"About us"},{"location":"about/#speakers","text":"","title":"Speakers"},{"location":"about/#nicolas-favier","text":"","title":"Nicolas Favier"},{"location":"about/#eric-ndouakulu-kiaku-mbuta","text":"","title":"Eric Ndouakulu Kiaku Mbuta"},{"location":"about/#benjamin-yvernault","text":"Benjamin recently left the world of data for the applications Web univers. He joined Takima beginning 2018. Takima is a consulting company specialised in fullstack development, DevOps, or Big Data. Since October 2018, he works at Mirakl, the leading provider of Marketplace Solutions. He joined one of the team developing the core system of the monolith.","title":"Benjamin Yvernault"},{"location":"about/#takima-mirakl-at-the-paris-devoxx-2019-come-see-us-in-person","text":"","title":"Takima &amp; Mirakl at the Paris DevoxX 2019: Come see us in person"},{"location":"setup/","text":"Setup to follow the HOMicS Github All the code for this HandsOn is hosted on github under the homics project. Java & Maven The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here . React & Node The front has been implemented in React . You don't need to play with it. You can find it in each frontend folders. We added a plugin in maven to build it with your backend application and both will be present on the same port. You need to install node . Docker & Docker-compose We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here .","title":"Setup"},{"location":"setup/#setup-to-follow-the-homics","text":"","title":"Setup to follow the HOMicS"},{"location":"setup/#github","text":"All the code for this HandsOn is hosted on github under the homics project.","title":"Github"},{"location":"setup/#java-maven","text":"The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here .","title":"Java &amp; Maven"},{"location":"setup/#react-node","text":"The front has been implemented in React . You don't need to play with it. You can find it in each frontend folders. We added a plugin in maven to build it with your backend application and both will be present on the same port. You need to install node .","title":"React &amp; Node"},{"location":"setup/#docker-docker-compose","text":"We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here .","title":"Docker &amp; Docker-compose"},{"location":"user-guide/gateway/","text":"Exercise 2 : Gateway Previously on HOMicS -> Exercise 1: User Activity Context In the previous schema, you might realize that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice ? You can go directly to user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But imagine if we have 20 microservices, it's going to be a mess if we need to add the security in each of them. The services won't be loosely coupled. It's where the gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway. Goal Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice. At your keyboard Use the final version for user-activity # Checkout the branch final user-activity$ git checkout final # Compile the front and back user-activity$ mvn clean install # Run the user-activity microservice user-activity$ mvn spring-boot:run You won't need to change anything on user. You can leave it running on the side. Setup the projects ... again Let's change the branch for the monolith . monolith $ git checkout exo2-gateway You can clone the repository for the gateway. git clone https://github.com/homics/gateway.git Same as before, some TODO are left in the code that you will need to fill. I think you remember this but let's do it again: mvn clean install to compile the front especially if you use an IDE. Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix that is an edge service that provides dynamic routing, monitoring, resiliency, security, and more. Spring integrated it in Spring Cloud . <dependency> <groupId>org.springframework.cloud</groupId> <artifactId>spring-cloud-starter-zuul</artifactId> </dependency> You will need to set it up in your application.yaml . zuul documentation is available here Update the WebSecurityConfig Check the configuration from the monolith. It should be quite identical. You might have to remove some /mono . Move authentication You remember what the Gateway is all about? Security and authentication, yes! You already worked on the security when you updated the WebSecurityConfig . Let's take care of the authentication. Don't be afraid, you basically need to move your files from the monolith to your gateway. Not too difficult. Now, your Gateway is going to take care of the login and will send an event to user-activity when there is a successful login or logout. Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Edit the UserFilter to retrieve this information in the monolith . Since the Gateway is running on port 8080, you need to change the port for the monolith to 8090. Monolith database You can access the monolith database console via the following url . Verification To verify that gateway is well implemented, launch all the applications: # Run monolith project monolith$ mvn spring-boot:run # Run user-activity project user-activity$ mvn spring-boot:run # Run Gateway project gateway$ mvn spring-boot:run Access the HOMicS MarketPlace . You should be on the gateway. After logging, you should be directly redirect to the monolith and you can notify that the port is still 8080. You should be able to access as well the user-activity microservice on the User Activity micro tab. You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done. Let's continue on to the next step. What's next ? Exercise 3: Stats","title":"exercise 2 - Gateway"},{"location":"user-guide/gateway/#exercise-2-gateway","text":"Previously on HOMicS -> Exercise 1: User Activity","title":"Exercise 2 : Gateway"},{"location":"user-guide/gateway/#context","text":"In the previous schema, you might realize that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice ? You can go directly to user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But imagine if we have 20 microservices, it's going to be a mess if we need to add the security in each of them. The services won't be loosely coupled. It's where the gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway.","title":"Context"},{"location":"user-guide/gateway/#goal","text":"Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice.","title":"Goal"},{"location":"user-guide/gateway/#at-your-keyboard","text":"Use the final version for user-activity # Checkout the branch final user-activity$ git checkout final # Compile the front and back user-activity$ mvn clean install # Run the user-activity microservice user-activity$ mvn spring-boot:run You won't need to change anything on user. You can leave it running on the side. Setup the projects ... again Let's change the branch for the monolith . monolith $ git checkout exo2-gateway You can clone the repository for the gateway. git clone https://github.com/homics/gateway.git Same as before, some TODO are left in the code that you will need to fill. I think you remember this but let's do it again: mvn clean install to compile the front especially if you use an IDE. Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix that is an edge service that provides dynamic routing, monitoring, resiliency, security, and more. Spring integrated it in Spring Cloud . <dependency> <groupId>org.springframework.cloud</groupId> <artifactId>spring-cloud-starter-zuul</artifactId> </dependency> You will need to set it up in your application.yaml . zuul documentation is available here Update the WebSecurityConfig Check the configuration from the monolith. It should be quite identical. You might have to remove some /mono . Move authentication You remember what the Gateway is all about? Security and authentication, yes! You already worked on the security when you updated the WebSecurityConfig . Let's take care of the authentication. Don't be afraid, you basically need to move your files from the monolith to your gateway. Not too difficult. Now, your Gateway is going to take care of the login and will send an event to user-activity when there is a successful login or logout. Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Edit the UserFilter to retrieve this information in the monolith . Since the Gateway is running on port 8080, you need to change the port for the monolith to 8090.","title":"At your keyboard"},{"location":"user-guide/gateway/#monolith-database","text":"You can access the monolith database console via the following url .","title":"Monolith database"},{"location":"user-guide/gateway/#verification","text":"To verify that gateway is well implemented, launch all the applications: # Run monolith project monolith$ mvn spring-boot:run # Run user-activity project user-activity$ mvn spring-boot:run # Run Gateway project gateway$ mvn spring-boot:run Access the HOMicS MarketPlace . You should be on the gateway. After logging, you should be directly redirect to the monolith and you can notify that the port is still 8080. You should be able to access as well the user-activity microservice on the User Activity micro tab. You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done. Let's continue on to the next step.","title":"Verification"},{"location":"user-guide/gateway/#whats-next-exercise-3-stats","text":"","title":"What's next ? Exercise 3: Stats"},{"location":"user-guide/kafka/","text":"Exercise 4 : Stats with Kafka Previously on HOMicS -> Exercise 3: Stats Context Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable. A word on KAFKA Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages. Goal We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which will consume the message. Setup Install Docker et Docker-compose For this exercise we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. Clone the common-messaging project : git clone https://github.com/homics/commons-messaging.git This repository contains the kafka configuration for our project with the docker-compose file to launch it. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd /tools/docker/kafka/ docker compose up To stop docker compose stop At your keyboard Add the common-messaging dependency to each project poms ( monolith and stats ): <!--All dependencies for kafka and messaging--> <dependency> <groupId>com.homics.commons-messaging</groupId> <artifactId>commons-messaging</artifactId> <version>1.0.0</version> </dependency> Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = \"statsMessageFactory\") public void onImpactStockMessage(@Payload OrderPayedMessage impactStockMessage) { ... } Save this message into the database Back to the monolith, remove StatsTask and OrderStat table and the related code. Verification To verify that stats with kafka is well implemented, - launch the monolith - pass some orders - start the microservice stats - verify that the stats are present and computed. What's next ? Exercise 5: Stock","title":"exercise 4 - Stats with Kafka"},{"location":"user-guide/kafka/#exercise-4-stats-with-kafka","text":"Previously on HOMicS -> Exercise 3: Stats","title":"Exercise 4 : Stats with Kafka"},{"location":"user-guide/kafka/#context","text":"Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable.","title":"Context"},{"location":"user-guide/kafka/#a-word-on-kafka","text":"Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages.","title":"A word on KAFKA"},{"location":"user-guide/kafka/#goal","text":"We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which will consume the message.","title":"Goal"},{"location":"user-guide/kafka/#setup","text":"Install Docker et Docker-compose For this exercise we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. Clone the common-messaging project : git clone https://github.com/homics/commons-messaging.git This repository contains the kafka configuration for our project with the docker-compose file to launch it. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd /tools/docker/kafka/ docker compose up To stop docker compose stop","title":"Setup"},{"location":"user-guide/kafka/#at-your-keyboard","text":"Add the common-messaging dependency to each project poms ( monolith and stats ): <!--All dependencies for kafka and messaging--> <dependency> <groupId>com.homics.commons-messaging</groupId> <artifactId>commons-messaging</artifactId> <version>1.0.0</version> </dependency> Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = \"statsMessageFactory\") public void onImpactStockMessage(@Payload OrderPayedMessage impactStockMessage) { ... } Save this message into the database Back to the monolith, remove StatsTask and OrderStat table and the related code.","title":"At your keyboard"},{"location":"user-guide/kafka/#verification","text":"To verify that stats with kafka is well implemented, - launch the monolith - pass some orders - start the microservice stats - verify that the stats are present and computed.","title":"Verification"},{"location":"user-guide/kafka/#whats-next-exercise-5-stock","text":"","title":"What's next ? Exercise 5: Stock"},{"location":"user-guide/monolith/","text":"Exercise 0 : The Monolith Fruit Market Place Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users. Architecture The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back. Keep in mind that you will need to recompile the front everytime you fetch a new exercise via the following command but no worries, we will put some reminders: mvn clean install Steps: Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/monolith.git Build your project: mvn clean install This will compute your front and back into a single application. Start your application (if you are using an IDE such as IntelliJ, you can run the application through it) : mvn spring-boot:run Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin . What's next ? Exercise 1: User Activity","title":"exercise 0 - Monolith"},{"location":"user-guide/monolith/#exercise-0-the-monolith","text":"","title":"Exercise 0 : The Monolith"},{"location":"user-guide/monolith/#fruit-market-place","text":"Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users.","title":"Fruit Market Place"},{"location":"user-guide/monolith/#architecture","text":"The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back. Keep in mind that you will need to recompile the front everytime you fetch a new exercise via the following command but no worries, we will put some reminders: mvn clean install","title":"Architecture"},{"location":"user-guide/monolith/#steps","text":"Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/monolith.git Build your project: mvn clean install This will compute your front and back into a single application. Start your application (if you are using an IDE such as IntelliJ, you can run the application through it) : mvn spring-boot:run Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin .","title":"Steps:"},{"location":"user-guide/monolith/#whats-next-exercise-1-user-activity","text":"","title":"What's next ? Exercise 1: User Activity"},{"location":"user-guide/stats/","text":"Exercise 3 : Stats Previously on HOMicS -> Exercise 2: Gateway Context In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it. Goal The monolith will save all the stats in a new table. Those stats will be hosted on a new microservice called stats . A schedule task fetch this table and send its content to the microservice. In case of error such as the downtime of the micro-service, the stats will be sent again at the next iteration. We are providing the microservice directly on github. You don't need to edit it. In terms of architecture: At your keyboard Setup Clone the stat repository. git clone https://github.com/homics/stats.git On the monolith checkout exo3-stat git checkout exo3-stat Complete the StatsTask : Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) Fill all TODOs in StatsService: The addOrderStat() saves the orderStat in H2. The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already worked with this template in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, create a class OrderPayedDto, it should match the one in stats microservice. A response status is HttpStatus.OK means the microservice received the information. Then, we remove it from the database. Clean the stats implementation that is not required anymore in the monolith. Database You can access the database console via the following url . Verification To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run monolith project monolith$ mvn spring-boot:run # Run gateway project gateway$ mvn spring-boot:run Access and login to the monolith . Execute two carts and pay them. The stats microservice isn't up and running at that point. Start the microservice: # Run stats project stats$ mvn spring-boot:run Navigate to the Stats Micro tab and you should see the same table than before with the stats from the previous two orders. All the stats should be retrieved. What's next ? Exercise 4: Stats with Kafka","title":"exercise 3 - Stats"},{"location":"user-guide/stats/#exercise-3-stats","text":"Previously on HOMicS -> Exercise 2: Gateway","title":"Exercise 3 : Stats"},{"location":"user-guide/stats/#context","text":"In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it.","title":"Context"},{"location":"user-guide/stats/#goal","text":"The monolith will save all the stats in a new table. Those stats will be hosted on a new microservice called stats . A schedule task fetch this table and send its content to the microservice. In case of error such as the downtime of the micro-service, the stats will be sent again at the next iteration. We are providing the microservice directly on github. You don't need to edit it. In terms of architecture:","title":"Goal"},{"location":"user-guide/stats/#at-your-keyboard","text":"Setup Clone the stat repository. git clone https://github.com/homics/stats.git On the monolith checkout exo3-stat git checkout exo3-stat Complete the StatsTask : Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) Fill all TODOs in StatsService: The addOrderStat() saves the orderStat in H2. The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already worked with this template in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, create a class OrderPayedDto, it should match the one in stats microservice. A response status is HttpStatus.OK means the microservice received the information. Then, we remove it from the database. Clean the stats implementation that is not required anymore in the monolith.","title":"At your keyboard"},{"location":"user-guide/stats/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/stats/#verification","text":"To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run monolith project monolith$ mvn spring-boot:run # Run gateway project gateway$ mvn spring-boot:run Access and login to the monolith . Execute two carts and pay them. The stats microservice isn't up and running at that point. Start the microservice: # Run stats project stats$ mvn spring-boot:run Navigate to the Stats Micro tab and you should see the same table than before with the stats from the previous two orders. All the stats should be retrieved.","title":"Verification"},{"location":"user-guide/stats/#whats-next-exercise-4-stats-with-kafka","text":"","title":"What's next ? Exercise 4: Stats with Kafka"},{"location":"user-guide/stock/","text":"Exercise 5 : Stock Previously on HOMicS -> Exercise 4: Stats with Kafka Context Often when splitting microservice the question of transactions arises. Let's try to discover why through the extraction of the stock microservice. About the stock micro-service Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article. The existing Before the migration when we pay an order we follow these steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction Classic extraction Now if we extract the stock service, the steps become : Open transaction Ask the micro service to impact the stock Wait the response Update the order status Close the transaction In this solution we wait for the microservice response. And it's bad! We avoid this solution because you don't want our server to wait on other microservices. For example if the call to impact stock time out, your payment method just wait the whole time and so is your user. So we change for asynchronous work. Going async Open transaction Ask the micro service to impact the stock Close the transaction The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction But what happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled. Goal Extract the stock micro service using kafka. So the workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verify and then impact the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consume this message and change the order status accordingly At your keyboard Remove the stock column in the monolith Implement the payment workflow previously describe in OrderService . (Topics and messages are already setup in the common-messaging lib) Implement the payment workflow on the micro service side in StockController Good to know When working with kafka we can choose the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. Here we work with the first one. To do so all our messages are idempotent. It means that the same message can be read multiple times and will give the same result. For example in the stats as the orderId is unique the second message only update the data. We need to do the same here it's why we keep the table StockOperation . What's next ? Come see us at our stand and let us know what you though about the Hands On. Please your feedback means a lot to us. If you have 5 mins to spare, could you fill this survey Thank you.","title":"exercise 5 - Stock"},{"location":"user-guide/stock/#exercise-5-stock","text":"Previously on HOMicS -> Exercise 4: Stats with Kafka","title":"Exercise 5 : Stock"},{"location":"user-guide/stock/#context","text":"Often when splitting microservice the question of transactions arises. Let's try to discover why through the extraction of the stock microservice.","title":"Context"},{"location":"user-guide/stock/#about-the-stock-micro-service","text":"Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article.","title":"About the stock micro-service"},{"location":"user-guide/stock/#the-existing","text":"Before the migration when we pay an order we follow these steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction","title":"The existing"},{"location":"user-guide/stock/#classic-extraction","text":"Now if we extract the stock service, the steps become : Open transaction Ask the micro service to impact the stock Wait the response Update the order status Close the transaction In this solution we wait for the microservice response. And it's bad! We avoid this solution because you don't want our server to wait on other microservices. For example if the call to impact stock time out, your payment method just wait the whole time and so is your user. So we change for asynchronous work.","title":"Classic extraction"},{"location":"user-guide/stock/#going-async","text":"Open transaction Ask the micro service to impact the stock Close the transaction The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction But what happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled.","title":"Going async"},{"location":"user-guide/stock/#goal","text":"Extract the stock micro service using kafka. So the workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verify and then impact the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consume this message and change the order status accordingly","title":"Goal"},{"location":"user-guide/stock/#at-your-keyboard","text":"Remove the stock column in the monolith Implement the payment workflow previously describe in OrderService . (Topics and messages are already setup in the common-messaging lib) Implement the payment workflow on the micro service side in StockController","title":"At your keyboard"},{"location":"user-guide/stock/#good-to-know","text":"When working with kafka we can choose the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. Here we work with the first one. To do so all our messages are idempotent. It means that the same message can be read multiple times and will give the same result. For example in the stats as the orderId is unique the second message only update the data. We need to do the same here it's why we keep the table StockOperation .","title":"Good to know"},{"location":"user-guide/stock/#whats-next","text":"Come see us at our stand and let us know what you though about the Hands On. Please your feedback means a lot to us. If you have 5 mins to spare, could you fill this survey Thank you.","title":"What's next ?"},{"location":"user-guide/user-activity/","text":"Exercise 1 : User Activity Previously on HOMicS -> Exercise 0: Monolith Context In our application, we track user activity on log in and log out. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomizeAuthenticationSuccessHandler and CustomizedLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler documentation here The front fetches those events for display through an internal API in UserActivityInternalController . Goal We are going to create a new service in charge of user activities. Let's be inventive and call it: user-activity. It will store all users activities in its own database and display the information on a dedicated page. The monolith will call this micro-service via API to notify on a success login or success logout. At your keyboard Setup the projects We are going back and forth between two projects: monolith and user-activity . First of all, clone the existing user-activity project from github where we set up the first exercise: git clone https://github.com/homics/user-activity.git TODO are left in the code that you need to be filled. Change the branch on the monolith to exo1-user : monolith $ git checkout exo1-user Do not forget to recompile the full project via mvn clean install to compile the front especially if you use an IDE. Edit user-activity application.yaml You need to configure the application.yaml so the microservice has a database, and run on port 9001. Check the application.yaml in the monolith to learn how to specify your database. Name the database dbuser . For the port, check out this . Complete UserActivityApiController & UserActivityInternalController For UserActivityInternalController , you need to add a post API to register the activity sent by the monolith. The DTO is already implemented: UserActivityDto . Use it. Complete UserActivityService You are asked to save and fetch user activities coming down from your controllers. Nothing fancy... Clean monolith: As a final step, you will clean the monolith to remove any code related to the user activity. We took care of the front for you. Yeah, the monolith is already thinner. But it's not over since the monolith does not speak with user-activity . On the monolith, edit CustomizeAuthenticationSuccessHandler and CustomizedLogoutSuccessHandler so the monolith call the microservice on each login and logout success. You should use: restTemplate.postForEntity(USER_ACTIVITY_URL, userActivity, Void.class); Great, you just created your first microservice and connected it to your monolith. Not too bad. Database You can access the database console via the following url . Verification To verify that user-activity is well implemented, launch both applications: # Run monolith project monolith$ mvn spring-boot:run # Run user-activity project user-activity$ mvn spring-boot:run Access and login to the monolith . Navigate to the User Activity Micro tab and you should see the same table than before. Troubleshooting If you have a 404 error, your front might not be compiled on your microservice. You remember our reminder on compiling it. Let's do it again here and run mvn clean install . What's next ? Exercise 2: Gateway","title":"exercise 1 - User Activity"},{"location":"user-guide/user-activity/#exercise-1-user-activity","text":"Previously on HOMicS -> Exercise 0: Monolith","title":"Exercise 1 : User Activity"},{"location":"user-guide/user-activity/#context","text":"In our application, we track user activity on log in and log out. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomizeAuthenticationSuccessHandler and CustomizedLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler documentation here The front fetches those events for display through an internal API in UserActivityInternalController .","title":"Context"},{"location":"user-guide/user-activity/#goal","text":"We are going to create a new service in charge of user activities. Let's be inventive and call it: user-activity. It will store all users activities in its own database and display the information on a dedicated page. The monolith will call this micro-service via API to notify on a success login or success logout.","title":"Goal"},{"location":"user-guide/user-activity/#at-your-keyboard","text":"Setup the projects We are going back and forth between two projects: monolith and user-activity . First of all, clone the existing user-activity project from github where we set up the first exercise: git clone https://github.com/homics/user-activity.git TODO are left in the code that you need to be filled. Change the branch on the monolith to exo1-user : monolith $ git checkout exo1-user Do not forget to recompile the full project via mvn clean install to compile the front especially if you use an IDE. Edit user-activity application.yaml You need to configure the application.yaml so the microservice has a database, and run on port 9001. Check the application.yaml in the monolith to learn how to specify your database. Name the database dbuser . For the port, check out this . Complete UserActivityApiController & UserActivityInternalController For UserActivityInternalController , you need to add a post API to register the activity sent by the monolith. The DTO is already implemented: UserActivityDto . Use it. Complete UserActivityService You are asked to save and fetch user activities coming down from your controllers. Nothing fancy... Clean monolith: As a final step, you will clean the monolith to remove any code related to the user activity. We took care of the front for you. Yeah, the monolith is already thinner. But it's not over since the monolith does not speak with user-activity . On the monolith, edit CustomizeAuthenticationSuccessHandler and CustomizedLogoutSuccessHandler so the monolith call the microservice on each login and logout success. You should use: restTemplate.postForEntity(USER_ACTIVITY_URL, userActivity, Void.class); Great, you just created your first microservice and connected it to your monolith. Not too bad.","title":"At your keyboard"},{"location":"user-guide/user-activity/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/user-activity/#verification","text":"To verify that user-activity is well implemented, launch both applications: # Run monolith project monolith$ mvn spring-boot:run # Run user-activity project user-activity$ mvn spring-boot:run Access and login to the monolith . Navigate to the User Activity Micro tab and you should see the same table than before.","title":"Verification"},{"location":"user-guide/user-activity/#troubleshooting","text":"If you have a 404 error, your front might not be compiled on your microservice. You remember our reminder on compiling it. Let's do it again here and run mvn clean install .","title":"Troubleshooting"},{"location":"user-guide/user-activity/#whats-next-exercise-2-gateway","text":"","title":"What's next ? Exercise 2: Gateway"}]}