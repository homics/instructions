{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to L'Atelier des Chefs: du monolith aux micro-services Homics -> Hands On Micro Service Subject Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices. Presentation Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github . What does microservice mean? Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey? Why microservice? It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Home"},{"location":"#welcome-to-latelier-des-chefs-du-monolith-aux-micro-services","text":"Homics -> Hands On Micro Service","title":"Welcome to L'Atelier des Chefs: du monolith aux micro-services"},{"location":"#subject","text":"Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices.","title":"Subject"},{"location":"#presentation","text":"Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github .","title":"Presentation"},{"location":"#what-does-microservice-mean","text":"Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey?","title":"What does microservice mean?"},{"location":"#why-microservice","text":"It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Why microservice?"},{"location":"about/","text":"About us Speakers Nicolas Favier Eric Ndouakulu Kiaku Mbuta Benjamin Yvernault Artus de Benque Takima & Mirakl at the Paris DevoxX 2019: Come see us in person","title":"About"},{"location":"about/#about-us","text":"","title":"About us"},{"location":"about/#speakers","text":"","title":"Speakers"},{"location":"about/#nicolas-favier","text":"","title":"Nicolas Favier"},{"location":"about/#eric-ndouakulu-kiaku-mbuta","text":"","title":"Eric Ndouakulu Kiaku Mbuta"},{"location":"about/#benjamin-yvernault","text":"","title":"Benjamin Yvernault"},{"location":"about/#artus-de-benque","text":"","title":"Artus de Benque"},{"location":"about/#takima-mirakl-at-the-paris-devoxx-2019-come-see-us-in-person","text":"","title":"Takima &amp; Mirakl at the Paris DevoxX 2019: Come see us in person"},{"location":"setup/","text":"Setup to follow the HOMicS Github All the code for this HandsOn is hosted on github under the homics project. You will need to install the git command line to checkout the code base and follow the HandsOn. Java & Maven The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here . Docker & Docker-compose We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here . CURL command You can set it up on windows via this link . It's available on macOs and Linux by default. Kubernetes To install minikube, select your OS and follow the instructions on how to install minikube . For MacOs users, don\u2019t forget to authorize virtualbox to enable its kernel extension on your computer via System Preferences \u2192 Security & Privacy \u2192 General, then restart the installation.","title":"Setup"},{"location":"setup/#setup-to-follow-the-homics","text":"","title":"Setup to follow the HOMicS"},{"location":"setup/#github","text":"All the code for this HandsOn is hosted on github under the homics project. You will need to install the git command line to checkout the code base and follow the HandsOn.","title":"Github"},{"location":"setup/#java-maven","text":"The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here .","title":"Java &amp; Maven"},{"location":"setup/#docker-docker-compose","text":"We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here .","title":"Docker &amp; Docker-compose"},{"location":"setup/#curl-command","text":"You can set it up on windows via this link . It's available on macOs and Linux by default.","title":"CURL command"},{"location":"setup/#kubernetes","text":"To install minikube, select your OS and follow the instructions on how to install minikube . For MacOs users, don\u2019t forget to authorize virtualbox to enable its kernel extension on your computer via System Preferences \u2192 Security & Privacy \u2192 General, then restart the installation.","title":"Kubernetes"},{"location":"troubleshooting/","text":"Troubleshooting Blank page when accessing the website If you have a 404 error, your front might not be compiled on your microservice. You need to recompile it via the following command: mvn clean install -P compile-front -pl $MICROSERVICE_NAME . Inconsistency in the database If you have an inconsistency in the database (something about hibernate and a resultSet at 2, you can try to restart your microservice. If it does not work, try to recompile everything with the front and restart the service. Issue with running the docker command If you see a permission issue when running the command docker to check if you properly sent the kafka message, you might need to run the command with sudo . (Don't forget to add the sudo on both docker commands).","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"troubleshooting/#blank-page-when-accessing-the-website","text":"If you have a 404 error, your front might not be compiled on your microservice. You need to recompile it via the following command: mvn clean install -P compile-front -pl $MICROSERVICE_NAME .","title":"Blank page when accessing the website"},{"location":"troubleshooting/#inconsistency-in-the-database","text":"If you have an inconsistency in the database (something about hibernate and a resultSet at 2, you can try to restart your microservice. If it does not work, try to recompile everything with the front and restart the service.","title":"Inconsistency in the database"},{"location":"troubleshooting/#issue-with-running-the-docker-command","text":"If you see a permission issue when running the command docker to check if you properly sent the kafka message, you might need to run the command with sudo . (Don't forget to add the sudo on both docker commands).","title":"Issue with running the docker command"},{"location":"user-guide/containers/","text":"Exercise 6 : Containers Previously on HOMicS -> Exercise 5: Stock Context We split our monolith into several microservices. Now, it's time to deploy this infrastructure. About the Containers A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. The container allow us to have independent and decoupled environment for each of our microservices. Goal Deploy our market place via docker. Reminder services port gateway 8080 monolith 8090 user 9001 stats 9002 stock 9003 At your keyboard Checkout the branch: git checkout exercise-6 Gateway's container 1 - Create your Dockerfile to build the docker image for gateway. You can find all the information you need on docker website with this two links step-2-create-a-dockerfile and build-an-image . For each microservice, you can use the following base image to deploy the app : openjdk:8u222-jre . 2 - Generate the docker image described by your Dockerfile docker build -t {image-name} {dockerfile-folder} # E.g: docker build -t \"gateway-image\" gateway 3 - Run a new container from your image docker run -d --name {container-name} -p {external-port}:{container-port} {image-name} # E.g: docker run -d --name gateway-container -p 9000:8080 gateway-image In this example, you will launch a new container for your gateway. The port 9000 of your computer is redirected to the port 8080 on your container. Check the docker's cheatsheet below: # Pull images from Hub docker pull {image-with-version} # Available docker's images docker images # Running container's listing docker ps # Remove a docker image docker rmi {image-id} # Remove a docker container docker rm {container-id} # Stop a docker container docker stop {container-id/container-name} # Kill a docker container docker kill {container-id/container-name} 4 - Verify on localhost:8080 that your gateway is running User-activity and Database Unlike gateway, User-activity required a database. Previously, it was an in-memory database h2. In real world, we need a persistent database. We already updated all our microservices to use a database on port 1521. Usually, each service comes with its database. It's one of the advantages of microservices. Each service can choose a database according to its needs. It allows your team more flexibility for the backup/deployment/upgrade. For simplicity, we are deploying a unique database. 1 - Run the containers for the database. The image already exists on a hub. You only need to run it with the following command: # Pull the image from the hub: docker pull oscarfonts/h2:1.4.197 # Run the container: docker run -d -p 1521:1521 -p 81:81 -v /tmp/data/homics-data:/opt/h2-data --name=homics-database oscarfonts/h2 2 - Create the user-activity dockerfile 3 - Generate the image and run the containers Go on localhost:8080 to access your gateway. Go on localhost:9001/user-activity to access user-activity page. Log on gateway and navigate to user-activity tab. 404 Not Found. The page isn't accessible and on user-activity, you don't see any new login. Why is that ? By default, docker's container runs on different networks so they cannot communicate directly with each other. For communication among containers, you can either manage routing at the OS level, or you can use an overlay network. We are going to use docker-compose to achieve this purpose. Docker-compose Compose is a tool for defining and running multi-container Docker applications. It deploys several containers within the same network described in a YAML file. In it, we list each application by its name and define how to build its container. For example, in this compose, we have one application named webapp : version: '3' services: webapp: image: my-webapp-image ports: - \"8080:8080\" 1 - Complete the docker-compose.yml Remember when we were routing our applications via Zuul in the gateway, we set the path for each of our microservices like http://localhost:9001/user . In our case, localhost becomes user . 2 - Update the gateway/application.yml , build the jar: ./buildJars gateway , and finally rebuild the docker image. 3 - Run the docker-compose: docker-compose up 4 - Navigate on localhost:8080 , log in, and verify that user-activity is accessible with the recent activity. Bonus: You can complete the docker-compose to deploy all microservices and kafka with a single command line. Be aware that this operation is CPU and RAM consuming to run everything. Some of you might encounter some difficulties. Good to know In a docker-compose, some applications might depend on others. For example, monolith depends on kafka and the database. You can specify that information by adding the keyword depends_on: : version: '3' services: webapp: image: my-webapp-image ports: - \"8080:8080\" depends_on: - database - kafka What's next ? Exercise 7: Kubernetes We are gonna see how to orchestrate everything automatically with Kubernetes.","title":"exercise 6 - Containers"},{"location":"user-guide/containers/#exercise-6-containers","text":"Previously on HOMicS -> Exercise 5: Stock","title":"Exercise 6 : Containers"},{"location":"user-guide/containers/#context","text":"We split our monolith into several microservices. Now, it's time to deploy this infrastructure.","title":"Context"},{"location":"user-guide/containers/#about-the-containers","text":"A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. The container allow us to have independent and decoupled environment for each of our microservices.","title":"About the Containers"},{"location":"user-guide/containers/#goal","text":"Deploy our market place via docker.","title":"Goal"},{"location":"user-guide/containers/#reminder","text":"services port gateway 8080 monolith 8090 user 9001 stats 9002 stock 9003","title":"Reminder"},{"location":"user-guide/containers/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-6","title":"At your keyboard"},{"location":"user-guide/containers/#gateways-container","text":"1 - Create your Dockerfile to build the docker image for gateway. You can find all the information you need on docker website with this two links step-2-create-a-dockerfile and build-an-image . For each microservice, you can use the following base image to deploy the app : openjdk:8u222-jre . 2 - Generate the docker image described by your Dockerfile docker build -t {image-name} {dockerfile-folder} # E.g: docker build -t \"gateway-image\" gateway 3 - Run a new container from your image docker run -d --name {container-name} -p {external-port}:{container-port} {image-name} # E.g: docker run -d --name gateway-container -p 9000:8080 gateway-image In this example, you will launch a new container for your gateway. The port 9000 of your computer is redirected to the port 8080 on your container. Check the docker's cheatsheet below: # Pull images from Hub docker pull {image-with-version} # Available docker's images docker images # Running container's listing docker ps # Remove a docker image docker rmi {image-id} # Remove a docker container docker rm {container-id} # Stop a docker container docker stop {container-id/container-name} # Kill a docker container docker kill {container-id/container-name} 4 - Verify on localhost:8080 that your gateway is running","title":"Gateway's container"},{"location":"user-guide/containers/#user-activity-and-database","text":"Unlike gateway, User-activity required a database. Previously, it was an in-memory database h2. In real world, we need a persistent database. We already updated all our microservices to use a database on port 1521. Usually, each service comes with its database. It's one of the advantages of microservices. Each service can choose a database according to its needs. It allows your team more flexibility for the backup/deployment/upgrade. For simplicity, we are deploying a unique database. 1 - Run the containers for the database. The image already exists on a hub. You only need to run it with the following command: # Pull the image from the hub: docker pull oscarfonts/h2:1.4.197 # Run the container: docker run -d -p 1521:1521 -p 81:81 -v /tmp/data/homics-data:/opt/h2-data --name=homics-database oscarfonts/h2 2 - Create the user-activity dockerfile 3 - Generate the image and run the containers Go on localhost:8080 to access your gateway. Go on localhost:9001/user-activity to access user-activity page. Log on gateway and navigate to user-activity tab. 404 Not Found. The page isn't accessible and on user-activity, you don't see any new login. Why is that ? By default, docker's container runs on different networks so they cannot communicate directly with each other. For communication among containers, you can either manage routing at the OS level, or you can use an overlay network. We are going to use docker-compose to achieve this purpose.","title":"User-activity and Database"},{"location":"user-guide/containers/#docker-compose","text":"Compose is a tool for defining and running multi-container Docker applications. It deploys several containers within the same network described in a YAML file. In it, we list each application by its name and define how to build its container. For example, in this compose, we have one application named webapp : version: '3' services: webapp: image: my-webapp-image ports: - \"8080:8080\" 1 - Complete the docker-compose.yml Remember when we were routing our applications via Zuul in the gateway, we set the path for each of our microservices like http://localhost:9001/user . In our case, localhost becomes user . 2 - Update the gateway/application.yml , build the jar: ./buildJars gateway , and finally rebuild the docker image. 3 - Run the docker-compose: docker-compose up 4 - Navigate on localhost:8080 , log in, and verify that user-activity is accessible with the recent activity.","title":"Docker-compose"},{"location":"user-guide/containers/#bonus","text":"You can complete the docker-compose to deploy all microservices and kafka with a single command line. Be aware that this operation is CPU and RAM consuming to run everything. Some of you might encounter some difficulties.","title":"Bonus:"},{"location":"user-guide/containers/#good-to-know","text":"In a docker-compose, some applications might depend on others. For example, monolith depends on kafka and the database. You can specify that information by adding the keyword depends_on: : version: '3' services: webapp: image: my-webapp-image ports: - \"8080:8080\" depends_on: - database - kafka","title":"Good to know"},{"location":"user-guide/containers/#whats-next-exercise-7-kubernetes","text":"We are gonna see how to orchestrate everything automatically with Kubernetes.","title":"What's next ? Exercise 7: Kubernetes"},{"location":"user-guide/gateway/","text":"Exercise 2 : Gateway Previously on HOMicS -> Exercise 1: User Activity Context In the previous schema, you might have realized that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice? Well you can access directly user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But it's not a scalable approach, we'd have to add it in all future microservices. And the services will be loosely coupled. This is where a Gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway, that will handle routing to our different services. Goal Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice. Everything has been implemented in other microservices. You only need to edit the gateway. At your keyboard Checkout the branch: git checkout exercise-2 There is a new folder for the gateway microservice. You won't have to start from scratch, but you will need to implement some parts. Start the gateway and the two other services monolith and user-activity in you IDE. Or with these commands (click to unfold): # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Browse the different pages. You'll realize that all pages return a 404 error. That's because there's no routing in our application. 2 - Gateway [todo 1] - Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix. It's an edge service that provides dynamic routing, monitoring, resiliency, security, among other things. Spring integrated it in Spring Cloud . You will need to set it up in your application.yaml . zuul documentation is available here To help you with the configuration in your yml file, here is an example: zuul: routes: testservice: path: /test/** url: http://example.com/test/ [todo 2] - Enable Zuul Checkout the second todo to enable the Zuul Routing. Checklist : Since the routing is done and should be working, start your three apps, if they aren't already up: # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Check that when login in, you see your articles as well as all other pages under the same port: 8080. What happens if you try to checkout a shopping cart? It doesn't work because the monolith doesn't know your user. Let's add it to our context in the next step. [todo 3] - Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Checklist : To check that the gateway is well implemented, launch all the applications with your IDE or via commands below. Click to unfold commands `mvn spring-boot:run -pl gateway` `mvn spring-boot:run -pl monolith` `mvn spring-boot:run -pl user-activity` Access the HOMicS MarketPlace . You should arrive on the gateway. After login in, you should be directly redirected to the monolith. You can note that the port is still 8080. You should also be able to access the user-activity microservice on the User Activity micro tab. Since the Gateway is running on port 8080, the port for the monolith has been changed to 8090. List of TODOs Todo File(s) 1 application.yaml for gateway 2 com.homics.gateway.GatewayApplication 3 com.homics.gateway.config.filter.AddUserFilter Monolith database You can access the monolith database console via the following url . Results You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done! Let's continue on to the next step, with a new microservices. What's next ? Exercise 3: Stats","title":"exercise 2 - Gateway"},{"location":"user-guide/gateway/#exercise-2-gateway","text":"Previously on HOMicS -> Exercise 1: User Activity","title":"Exercise 2 : Gateway"},{"location":"user-guide/gateway/#context","text":"In the previous schema, you might have realized that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice? Well you can access directly user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But it's not a scalable approach, we'd have to add it in all future microservices. And the services will be loosely coupled. This is where a Gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway, that will handle routing to our different services.","title":"Context"},{"location":"user-guide/gateway/#goal","text":"Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice. Everything has been implemented in other microservices. You only need to edit the gateway.","title":"Goal"},{"location":"user-guide/gateway/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-2 There is a new folder for the gateway microservice. You won't have to start from scratch, but you will need to implement some parts. Start the gateway and the two other services monolith and user-activity in you IDE. Or with these commands (click to unfold): # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Browse the different pages. You'll realize that all pages return a 404 error. That's because there's no routing in our application.","title":"At your keyboard"},{"location":"user-guide/gateway/#2-gateway","text":"[todo 1] - Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix. It's an edge service that provides dynamic routing, monitoring, resiliency, security, among other things. Spring integrated it in Spring Cloud . You will need to set it up in your application.yaml . zuul documentation is available here To help you with the configuration in your yml file, here is an example: zuul: routes: testservice: path: /test/** url: http://example.com/test/ [todo 2] - Enable Zuul Checkout the second todo to enable the Zuul Routing. Checklist : Since the routing is done and should be working, start your three apps, if they aren't already up: # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Check that when login in, you see your articles as well as all other pages under the same port: 8080. What happens if you try to checkout a shopping cart? It doesn't work because the monolith doesn't know your user. Let's add it to our context in the next step. [todo 3] - Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Checklist : To check that the gateway is well implemented, launch all the applications with your IDE or via commands below. Click to unfold commands `mvn spring-boot:run -pl gateway` `mvn spring-boot:run -pl monolith` `mvn spring-boot:run -pl user-activity` Access the HOMicS MarketPlace . You should arrive on the gateway. After login in, you should be directly redirected to the monolith. You can note that the port is still 8080. You should also be able to access the user-activity microservice on the User Activity micro tab. Since the Gateway is running on port 8080, the port for the monolith has been changed to 8090.","title":"2 - Gateway"},{"location":"user-guide/gateway/#list-of-todos","text":"Todo File(s) 1 application.yaml for gateway 2 com.homics.gateway.GatewayApplication 3 com.homics.gateway.config.filter.AddUserFilter","title":"List of TODOs"},{"location":"user-guide/gateway/#monolith-database","text":"You can access the monolith database console via the following url .","title":"Monolith database"},{"location":"user-guide/gateway/#results","text":"You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done! Let's continue on to the next step, with a new microservices.","title":"Results"},{"location":"user-guide/gateway/#whats-next-exercise-3-stats","text":"","title":"What's next ? Exercise 3: Stats"},{"location":"user-guide/kafka/","text":"Exercise 4 : Stats with Kafka Previously on HOMicS -> Exercise 3: Stats Context Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable. A word on KAFKA Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages. Goal We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which consumes the message. At your keyboard Checkout the branch: git checkout exercise-4 This exercise is split in two parts. You will edit the Monolith to send a message to kafka when an order is payed. You will consume the messages in the Stats microservice. Setup Before implementing anything, for this exercise, we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. If you want to check it out, go on github in the HOMicS project. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd commons-messaging docker-compose up To stop cd commons-messaging docker-compose stop 4.1 - Monolith [todo 1] - Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); Checklist Verify that you sent a kafka message You can verify the creation of your message by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STATS --from-beginning You should see the previous carts you payed. 4.2 - Stats [todo 2] - In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = STATS_MESSAGE_FACTORY) public void onStatsMessage(@Payload OrderPayedMessage impactStockMessage) { ... } [todo 3] - Save this message into the database. List of TODOs Todo File(s) 1 com.homics.monolith.service.StatsService 2 com.homics.stats.service.OrderStatsService 3 com.homics.stats.service.OrderStatsService Verification and results To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run gateway project mvn spring-boot:run -pl gateway # Run monolith project mvn spring-boot:run -pl monolith Login to the application on the login page . Create two carts and pay for them. You see a 404 page on the Stats Micro tab. The stats microservice isn't up and running at that point. This behaviour makes sense. Now, start the microservice Stats : # Run stats project mvn spring-boot:run -pl stats Navigate to the Stats Micro tab. You should see the same page than before with the stats from the previous two orders. All the stats should be retrieved. If you don't see them, refresh few times to let the monolith discuss with the microservice . It's exactly the same actions than exercise 3. What's next ? Exercise 5: Stock","title":"exercise 4 - Stats with Kafka"},{"location":"user-guide/kafka/#exercise-4-stats-with-kafka","text":"Previously on HOMicS -> Exercise 3: Stats","title":"Exercise 4 : Stats with Kafka"},{"location":"user-guide/kafka/#context","text":"Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable.","title":"Context"},{"location":"user-guide/kafka/#a-word-on-kafka","text":"Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages.","title":"A word on KAFKA"},{"location":"user-guide/kafka/#goal","text":"We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which consumes the message.","title":"Goal"},{"location":"user-guide/kafka/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-4 This exercise is split in two parts. You will edit the Monolith to send a message to kafka when an order is payed. You will consume the messages in the Stats microservice.","title":"At your keyboard"},{"location":"user-guide/kafka/#setup","text":"Before implementing anything, for this exercise, we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. If you want to check it out, go on github in the HOMicS project. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd commons-messaging docker-compose up To stop cd commons-messaging docker-compose stop","title":"Setup"},{"location":"user-guide/kafka/#41-monolith","text":"[todo 1] - Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); Checklist Verify that you sent a kafka message You can verify the creation of your message by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STATS --from-beginning You should see the previous carts you payed.","title":"4.1 - Monolith"},{"location":"user-guide/kafka/#42-stats","text":"[todo 2] - In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = STATS_MESSAGE_FACTORY) public void onStatsMessage(@Payload OrderPayedMessage impactStockMessage) { ... } [todo 3] - Save this message into the database.","title":"4.2 - Stats"},{"location":"user-guide/kafka/#list-of-todos","text":"Todo File(s) 1 com.homics.monolith.service.StatsService 2 com.homics.stats.service.OrderStatsService 3 com.homics.stats.service.OrderStatsService","title":"List of TODOs"},{"location":"user-guide/kafka/#verification-and-results","text":"To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run gateway project mvn spring-boot:run -pl gateway # Run monolith project mvn spring-boot:run -pl monolith Login to the application on the login page . Create two carts and pay for them. You see a 404 page on the Stats Micro tab. The stats microservice isn't up and running at that point. This behaviour makes sense. Now, start the microservice Stats : # Run stats project mvn spring-boot:run -pl stats Navigate to the Stats Micro tab. You should see the same page than before with the stats from the previous two orders. All the stats should be retrieved. If you don't see them, refresh few times to let the monolith discuss with the microservice . It's exactly the same actions than exercise 3.","title":"Verification and results"},{"location":"user-guide/kafka/#whats-next-exercise-5-stock","text":"","title":"What's next ? Exercise 5: Stock"},{"location":"user-guide/kubernetes/","text":"Exercise 7: Kubernetes Previously on HOMicS -> Exercise 6: Containers Context We saw on the previous exercises how to run our applications using containers and docker. Maybe you noticed the Crash button on user-activity tab. Surprisingly, this button will crash your application. It's our way to mock production crashes like OutOfMemory, StackOverflow, hardware failures, etc ... When it happens, you need to manually reboot your container. In production, this is not acceptable. Let's discover how Kubernetes can automatize this process. About Kubernetes Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. Kubernetes provides you with a framework to run distributed systems resiliently. We are not going to explain every concept behind it but we will introduce some key notions before starting the exercise. Kubernetes documentation is very well designed and will probably answer most of your questions. First of all, a pod is the most basic unit in kubernetes. It can encapsulate one or more containers that are tightly coupled and that share resources. In our case, one pod corresponds to one container, meaning one single instance of an application. We can have several pods of the same application that are called replicas . There are the key of resilience and availability. Kube manages on which machines the pod and its replicas are running. Those machines (VM or physical) are named Nodes . Kube provides two other objects, Deployment and Service . Deployment describes a desire state of a cluster like the number of replicas. A service defines a logical set of Pods and a policy by which to access them. Minikube Minikube is a tool that runs a single-node Kubernetes cluster in a virtual machine on your personal computer. To set it up, go back to Setup . CheatSheet : # Minikube start (or stop) minikube start # Get the state of your pods kubectl get pod # Get the state of your deployments kubectl get deploy # Get the state of your services kubectl get service # Apply a deployment or a service kubectl apply -f file.yml # Delete a deployment kubectl delete deploy {deployment-name} # Delete a service kubectl delete service {service-name} # Describe an object kubectl describe service {service-name} # Get the logs kubectl logs {pod-name} # Minikube launch the service page minikube service {service-name} Goal Automatize the deployment of our market place using Kubernetes. At your keyboard Checkout the branch: git checkout exercise-7 All the docker's images are available on docker hub under the following names: Services Docker image name gateway homics/gateway:1.0.0 monolith homics/monolith:1.0.0 user homics/user-activity:1.0.0 stats homics/stats:1.0.0 stock homics/stock:1.0.0 Gateway 1 - Create a deployment.yml file for gateway and run kubectl apply -f deployment.yml You can find everything you need on Kubernetes documentation Writing a deployment . If you run kubectl get deploy and kubectl get pod , you should get something similar to: > kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE gateway-deployment 1/1 1 1 30s > kubectl get pod NAME READY STATUS RESTARTS AGE gateway-deployment-7895c9c479-bdztx 1/1 Running 0 30s Above, we see that you have one deployment running, that is up to date with one pod available. This pod is in the state Ready and Running with no restart. The pod has been created 30 seconds ago. Unfortunately, at this step, you can't access your gateway from your browser. To access your pod from the outside, we need to define a service. 2 - Create a service.yml file for gateway and run kubectl apply -f service.yml You can find everything you need on Kubernetes documentation Writing a service . A service is defined by its type. By default, it is ClusterIp which means your pod is accessible only in your cluster. In some parts of our application (the front), we might need to expose our service to the outside world. For this case, you can specify a different type such as NodePort or LoadBalancer . In our case, we will use NodePort. spec: type: NodePort ports: ... Run kubectl get service to see your newly created services Run minikube service gateway to access your gateway. User and Database 1 - Create a deployment and service for User and the database. 2 - Crash you application by accessing User-Activity tab and clicking on the button. You realize that the page is not accessible anymore and when you run kubectl get pod , you can see: NAME READY STATUS RESTARTS AGE gateway-deployment-7895c9c479-bdztx 1/1 Running 0 5m31s homics-db-deployment-7bbf5fc44b-zggs4 1/1 Running 0 3m15s user-deployment-7889589595-pzkv5 0/1 Running 1 3m10s Your user-pod is running but the number ready is 0/1. Your pod isn't accessible and you can see that the number of restarts increased to one. You pod is restarting automatically. In few seconds, you should see again your activity's page. Rolling Update for User Your application keeps evolving through time and you often need to update it. Unfortunately, you don't want to call your client and tell him that you need to shutdown the app for few seconds/minutes. Kube manages rolling updates very efficiently. It creates a new pod, install the new version, and then move the traffic from the old pod to the new one, to finally kill the old one. No downtime, great. Let's roll user's app with its version 2.0.0. 1 - Open the user-activity tab and click on version button. It prints the version of your app every second. 2 - Run kubectl set image deployments/user-deployment user=homics/user-activity:2.0.0 And the version should change from 1.0.0 to 2.0.0 on the user-activity page but you realize that there are some lines Error calling the server . What happens ? Kube does not know when a pod is actually ready. The traffic is directed to the new pod even so the spring app is still starting. Kube defines the notion of readiness in a deployment file. You can specify when an app is ready and Kube won't allow access on the pod before the condition is met. You can check How to define readiness probes . In our case, our pod is ready when we can access /user/internal/version on port 9001 of our application. 3 - Set back the image to 1.0.0 and see that you don't have any error. Replicas and crashes While crashing your application, you realize that we had some downtime. When we introduce the term of replica, we define them as the key for resilience and availability. Right now, User pod isn't available if one pod crashes. We are going to increase the number of replica to 2. 1 - Increase the number of replica to 2 in your deployment.yml 2 - Crash your application and reload the page You realize that the service is always available. Bonus: Deploy our market place Since you finish all the different steps of this last exercise, you can keep going by deploying all our microservices into minikube. Start with monolith and kafka. Add stats and stock. Trouble shooting : If you encounter the error : invalid object doesn't have additional properties you need to relink kubectl : brew link --overwrite kubernetes-cli Good to know // todo What's next ? Come see us after hand and let us know what you though about the Hands On. Thank you.","title":"exercise 7 - Kubernetes"},{"location":"user-guide/kubernetes/#exercise-7-kubernetes","text":"Previously on HOMicS -> Exercise 6: Containers","title":"Exercise 7: Kubernetes"},{"location":"user-guide/kubernetes/#context","text":"We saw on the previous exercises how to run our applications using containers and docker. Maybe you noticed the Crash button on user-activity tab. Surprisingly, this button will crash your application. It's our way to mock production crashes like OutOfMemory, StackOverflow, hardware failures, etc ... When it happens, you need to manually reboot your container. In production, this is not acceptable. Let's discover how Kubernetes can automatize this process.","title":"Context"},{"location":"user-guide/kubernetes/#about-kubernetes","text":"Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. Kubernetes provides you with a framework to run distributed systems resiliently. We are not going to explain every concept behind it but we will introduce some key notions before starting the exercise. Kubernetes documentation is very well designed and will probably answer most of your questions. First of all, a pod is the most basic unit in kubernetes. It can encapsulate one or more containers that are tightly coupled and that share resources. In our case, one pod corresponds to one container, meaning one single instance of an application. We can have several pods of the same application that are called replicas . There are the key of resilience and availability. Kube manages on which machines the pod and its replicas are running. Those machines (VM or physical) are named Nodes . Kube provides two other objects, Deployment and Service . Deployment describes a desire state of a cluster like the number of replicas. A service defines a logical set of Pods and a policy by which to access them.","title":"About Kubernetes"},{"location":"user-guide/kubernetes/#minikube","text":"Minikube is a tool that runs a single-node Kubernetes cluster in a virtual machine on your personal computer. To set it up, go back to Setup . CheatSheet : # Minikube start (or stop) minikube start # Get the state of your pods kubectl get pod # Get the state of your deployments kubectl get deploy # Get the state of your services kubectl get service # Apply a deployment or a service kubectl apply -f file.yml # Delete a deployment kubectl delete deploy {deployment-name} # Delete a service kubectl delete service {service-name} # Describe an object kubectl describe service {service-name} # Get the logs kubectl logs {pod-name} # Minikube launch the service page minikube service {service-name}","title":"Minikube"},{"location":"user-guide/kubernetes/#goal","text":"Automatize the deployment of our market place using Kubernetes.","title":"Goal"},{"location":"user-guide/kubernetes/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-7 All the docker's images are available on docker hub under the following names: Services Docker image name gateway homics/gateway:1.0.0 monolith homics/monolith:1.0.0 user homics/user-activity:1.0.0 stats homics/stats:1.0.0 stock homics/stock:1.0.0","title":"At your keyboard"},{"location":"user-guide/kubernetes/#gateway","text":"1 - Create a deployment.yml file for gateway and run kubectl apply -f deployment.yml You can find everything you need on Kubernetes documentation Writing a deployment . If you run kubectl get deploy and kubectl get pod , you should get something similar to: > kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE gateway-deployment 1/1 1 1 30s > kubectl get pod NAME READY STATUS RESTARTS AGE gateway-deployment-7895c9c479-bdztx 1/1 Running 0 30s Above, we see that you have one deployment running, that is up to date with one pod available. This pod is in the state Ready and Running with no restart. The pod has been created 30 seconds ago. Unfortunately, at this step, you can't access your gateway from your browser. To access your pod from the outside, we need to define a service. 2 - Create a service.yml file for gateway and run kubectl apply -f service.yml You can find everything you need on Kubernetes documentation Writing a service . A service is defined by its type. By default, it is ClusterIp which means your pod is accessible only in your cluster. In some parts of our application (the front), we might need to expose our service to the outside world. For this case, you can specify a different type such as NodePort or LoadBalancer . In our case, we will use NodePort. spec: type: NodePort ports: ... Run kubectl get service to see your newly created services Run minikube service gateway to access your gateway.","title":"Gateway"},{"location":"user-guide/kubernetes/#user-and-database","text":"1 - Create a deployment and service for User and the database. 2 - Crash you application by accessing User-Activity tab and clicking on the button. You realize that the page is not accessible anymore and when you run kubectl get pod , you can see: NAME READY STATUS RESTARTS AGE gateway-deployment-7895c9c479-bdztx 1/1 Running 0 5m31s homics-db-deployment-7bbf5fc44b-zggs4 1/1 Running 0 3m15s user-deployment-7889589595-pzkv5 0/1 Running 1 3m10s Your user-pod is running but the number ready is 0/1. Your pod isn't accessible and you can see that the number of restarts increased to one. You pod is restarting automatically. In few seconds, you should see again your activity's page.","title":"User and Database"},{"location":"user-guide/kubernetes/#rolling-update-for-user","text":"Your application keeps evolving through time and you often need to update it. Unfortunately, you don't want to call your client and tell him that you need to shutdown the app for few seconds/minutes. Kube manages rolling updates very efficiently. It creates a new pod, install the new version, and then move the traffic from the old pod to the new one, to finally kill the old one. No downtime, great. Let's roll user's app with its version 2.0.0. 1 - Open the user-activity tab and click on version button. It prints the version of your app every second. 2 - Run kubectl set image deployments/user-deployment user=homics/user-activity:2.0.0 And the version should change from 1.0.0 to 2.0.0 on the user-activity page but you realize that there are some lines Error calling the server . What happens ? Kube does not know when a pod is actually ready. The traffic is directed to the new pod even so the spring app is still starting. Kube defines the notion of readiness in a deployment file. You can specify when an app is ready and Kube won't allow access on the pod before the condition is met. You can check How to define readiness probes . In our case, our pod is ready when we can access /user/internal/version on port 9001 of our application. 3 - Set back the image to 1.0.0 and see that you don't have any error.","title":"Rolling Update for User"},{"location":"user-guide/kubernetes/#replicas-and-crashes","text":"While crashing your application, you realize that we had some downtime. When we introduce the term of replica, we define them as the key for resilience and availability. Right now, User pod isn't available if one pod crashes. We are going to increase the number of replica to 2. 1 - Increase the number of replica to 2 in your deployment.yml 2 - Crash your application and reload the page You realize that the service is always available.","title":"Replicas and crashes"},{"location":"user-guide/kubernetes/#bonus-deploy-our-market-place","text":"Since you finish all the different steps of this last exercise, you can keep going by deploying all our microservices into minikube. Start with monolith and kafka. Add stats and stock.","title":"Bonus: Deploy our market place"},{"location":"user-guide/kubernetes/#trouble-shooting","text":"If you encounter the error : invalid object doesn't have additional properties you need to relink kubectl : brew link --overwrite kubernetes-cli","title":"Trouble shooting :"},{"location":"user-guide/kubernetes/#good-to-know","text":"// todo","title":"Good to know"},{"location":"user-guide/kubernetes/#whats-next","text":"Come see us after hand and let us know what you though about the Hands On. Thank you.","title":"What's next ?"},{"location":"user-guide/monolith/","text":"Exercise 0 : The Monolith Fruit Market Place Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users. Architecture The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back. Steps: Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/handson.git Start your application via IDE ( MonolithApplication.java ), or with this command line: mvn spring-boot:run -pl monolith Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin . What's next ? Exercise 1: User Activity","title":"exercise 0 - Monolith"},{"location":"user-guide/monolith/#exercise-0-the-monolith","text":"","title":"Exercise 0 : The Monolith"},{"location":"user-guide/monolith/#fruit-market-place","text":"Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users.","title":"Fruit Market Place"},{"location":"user-guide/monolith/#architecture","text":"The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back.","title":"Architecture"},{"location":"user-guide/monolith/#steps","text":"Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/handson.git Start your application via IDE ( MonolithApplication.java ), or with this command line: mvn spring-boot:run -pl monolith Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin .","title":"Steps:"},{"location":"user-guide/monolith/#whats-next-exercise-1-user-activity","text":"","title":"What's next ? Exercise 1: User Activity"},{"location":"user-guide/stats/","text":"Exercise 3 : Stats Previously on HOMicS -> Exercise 2: Gateway Context In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it. Goal The monolith will save all the stats in a new table. These stats will be hosted on a new microservice called stats . A scheduled task fetches this table and sends its content to the microservice. In case of micro-service downtime or errors while processing, the stats will be sent again at the next iteration. We implemented the stats microservice. You don't need to work on it in this exercise. In terms of architecture: At your keyboard Checkout the branch git checkout exercise-3 Start the gateway and the two services stats and user-activity. # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity 3 - Monolith [todo 1] - You need to save an orderPayMessage in the database. [todo 2] - Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) For more information, visit this link . [todo 3] - The last implementation on your part is to complete the two methods sendStats and sendStat . The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already used restTemplate in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, use the class OrderPayedDto. A response status HttpStatus.OK means the microservice received the information. Then, we remove it from the database. [todo 4] - Clean Remove the code related to stats that is not required anymore in the monolith. List of TODOs Todo File(s) 1 com.homics.monolith.service.StatsService 2 com.homics.monolith.task.StatsTask 3 com.homics.monolith.service.StatsService 4 com.homics.monolith.service.OrderService / com.homics.monolith.controller.dto.OrderStatsDto Database You can access the database console via the following url . Verification and results To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run gateway project mvn spring-boot:run -pl gateway # Run monolith project mvn spring-boot:run -pl monolith Login to the application on the login page . Create two carts and pay for them. You see a 404 page on the Stats Micro tab. The stats microservice isn't up and running at that point. This behaviour makes sense. Now, start the microservice Stats : # Run stats project mvn spring-boot:run -pl stats Navigate to the Stats Micro tab. You should see the same page than before with the stats from the previous two orders. All the stats should be retrieved. If you don't see them, refresh few times to let the monolith discuss with the microservice Great. It works like a charm. But let's see an other way of doing this. What's next ? Exercise 4: Stats with Kafka","title":"exercise 3 - Stats"},{"location":"user-guide/stats/#exercise-3-stats","text":"Previously on HOMicS -> Exercise 2: Gateway","title":"Exercise 3 : Stats"},{"location":"user-guide/stats/#context","text":"In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it.","title":"Context"},{"location":"user-guide/stats/#goal","text":"The monolith will save all the stats in a new table. These stats will be hosted on a new microservice called stats . A scheduled task fetches this table and sends its content to the microservice. In case of micro-service downtime or errors while processing, the stats will be sent again at the next iteration. We implemented the stats microservice. You don't need to work on it in this exercise. In terms of architecture:","title":"Goal"},{"location":"user-guide/stats/#at-your-keyboard","text":"Checkout the branch git checkout exercise-3 Start the gateway and the two services stats and user-activity. # gateway mvn spring-boot:run -pl gateway # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity","title":"At your keyboard"},{"location":"user-guide/stats/#3-monolith","text":"[todo 1] - You need to save an orderPayMessage in the database. [todo 2] - Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) For more information, visit this link . [todo 3] - The last implementation on your part is to complete the two methods sendStats and sendStat . The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already used restTemplate in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, use the class OrderPayedDto. A response status HttpStatus.OK means the microservice received the information. Then, we remove it from the database. [todo 4] - Clean Remove the code related to stats that is not required anymore in the monolith.","title":"3 - Monolith"},{"location":"user-guide/stats/#list-of-todos","text":"Todo File(s) 1 com.homics.monolith.service.StatsService 2 com.homics.monolith.task.StatsTask 3 com.homics.monolith.service.StatsService 4 com.homics.monolith.service.OrderService / com.homics.monolith.controller.dto.OrderStatsDto","title":"List of TODOs"},{"location":"user-guide/stats/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/stats/#verification-and-results","text":"To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run gateway project mvn spring-boot:run -pl gateway # Run monolith project mvn spring-boot:run -pl monolith Login to the application on the login page . Create two carts and pay for them. You see a 404 page on the Stats Micro tab. The stats microservice isn't up and running at that point. This behaviour makes sense. Now, start the microservice Stats : # Run stats project mvn spring-boot:run -pl stats Navigate to the Stats Micro tab. You should see the same page than before with the stats from the previous two orders. All the stats should be retrieved. If you don't see them, refresh few times to let the monolith discuss with the microservice Great. It works like a charm. But let's see an other way of doing this.","title":"Verification and results"},{"location":"user-guide/stats/#whats-next-exercise-4-stats-with-kafka","text":"","title":"What's next ? Exercise 4: Stats with Kafka"},{"location":"user-guide/stock/","text":"Exercise 5 : Stock Previously on HOMicS -> Exercise 4: Stats with Kafka Context Often when splitting microservice, the question of transactions arises. Let's try to discover why through the extraction of the stock microservice. About the stock micro-service Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article. The existing Before the migration when we pay an order, we were executing the following steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction Extract it into a microservice If we extract the stock service in a microservice like we did before, the steps become : Open transaction Ask the micro service to impact the stock Wait for the response Update the order status Close the transaction With this plan, you can see in step 3 that the monolith is waiting for the microservice response. It's pretty bad! Imagine that the call to impact stock times out... Your payment method is going to wait the whole time and so is your user. We need to change to asynchronous. Going async Open transaction Ask the micro service to impact the stock Close the transaction Then, we listen to the microservice event. The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction What happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled. Goal Extract the stock micro service using kafka. The workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verifies and then impacts the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consumes the message and change the order status accordingly At your keyboard Checkout the branch: git checkout exercise-5 This exercise is split in three parts. You will edit the Monolith to remove the stock and send a message when paying the order to decrease the stock. You will consume the messages in the Stock microservice to decrease the stock and answer with a new message for acknowledgement. Go back to the Monolith and consume the answer from Stock and perform the stats if success. 5.1 - Monolith [todo 1] - Remove the stock column in the Article entity. [todo 2] - Remove the stock validation and call the StockService. [todo 3] - Implement the method to send a kafka message to the Stock microservice Checklist 1. Verify that you sent a kafka message You can verify the creation of your message by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STOCK --from-beginning You should see the message you sent to the stock microservice. 5.2 - Stock [todo 4] - Consume the message and call the stock service. [todo 5] - Verify that the operation wasn't already process to keep an idempotent process. [todo 6] - Notify by calling the right method to acknowledge the changes on stock. [todo 7] - Notify by sending a message to kafka that stock could NOT be modified. [todo 8] - Save the operation as processed so it won't be process several times. [todo 9] - Notify by sending a message to kafka that stock was modified successfully. Checklist 1. Verify that you sent a kafka message You can verify the creation of your messages by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STOCK --from-beginning You should see the messages you sent for acknowledgement and stock's modification. 5.3 - Monolith [todo 10] - Depending on the message sent by Stock for acknowledgement, set the status for the order ( PAYED or CANCEL ) [todo 11] - In case of success, update the stats and notify the stats microservice. List of TODOs Todo File(s) 1 com.homics.monolith.model.Article 2 com.homics.monolith.service.OrderService 3 com.homics.monolith.service.StockService 4 com.homics.stock.service.ImpactStockConsumer 5 com.homics.stock.service.StockService 6 com.homics.stock.service.StockService 7 com.homics.stock.service.StockService 8 com.homics.stock.service.StockService 9 com.homics.stock.service.StockAcknowledgmentProducer 10 com.homics.stock.service.OrderService 11 com.homics.monolith.service.OrderService Good to know When working with kafka, we can set the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. We are working with the first choice. It constrains us to have idempotent messages. Idempotent means that an action always gives the same result even if you played several times. In our case, the same message can be read multiple times and will give the same result. For example, in the stats microservice, the second message only updates the data since the orderId is unique. It explains why we keep the table StockOperation . What's next ? Exercise 6: Containers Let's deploy our market place in containers.","title":"exercise 5 - Stock"},{"location":"user-guide/stock/#exercise-5-stock","text":"Previously on HOMicS -> Exercise 4: Stats with Kafka","title":"Exercise 5 : Stock"},{"location":"user-guide/stock/#context","text":"Often when splitting microservice, the question of transactions arises. Let's try to discover why through the extraction of the stock microservice.","title":"Context"},{"location":"user-guide/stock/#about-the-stock-micro-service","text":"Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article.","title":"About the stock micro-service"},{"location":"user-guide/stock/#the-existing","text":"Before the migration when we pay an order, we were executing the following steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction","title":"The existing"},{"location":"user-guide/stock/#extract-it-into-a-microservice","text":"If we extract the stock service in a microservice like we did before, the steps become : Open transaction Ask the micro service to impact the stock Wait for the response Update the order status Close the transaction With this plan, you can see in step 3 that the monolith is waiting for the microservice response. It's pretty bad! Imagine that the call to impact stock times out... Your payment method is going to wait the whole time and so is your user. We need to change to asynchronous.","title":"Extract it into a microservice"},{"location":"user-guide/stock/#going-async","text":"Open transaction Ask the micro service to impact the stock Close the transaction Then, we listen to the microservice event. The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction What happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled.","title":"Going async"},{"location":"user-guide/stock/#goal","text":"Extract the stock micro service using kafka. The workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verifies and then impacts the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consumes the message and change the order status accordingly","title":"Goal"},{"location":"user-guide/stock/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-5 This exercise is split in three parts. You will edit the Monolith to remove the stock and send a message when paying the order to decrease the stock. You will consume the messages in the Stock microservice to decrease the stock and answer with a new message for acknowledgement. Go back to the Monolith and consume the answer from Stock and perform the stats if success.","title":"At your keyboard"},{"location":"user-guide/stock/#51-monolith","text":"[todo 1] - Remove the stock column in the Article entity. [todo 2] - Remove the stock validation and call the StockService. [todo 3] - Implement the method to send a kafka message to the Stock microservice Checklist 1. Verify that you sent a kafka message You can verify the creation of your message by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STOCK --from-beginning You should see the message you sent to the stock microservice.","title":"5.1 - Monolith"},{"location":"user-guide/stock/#52-stock","text":"[todo 4] - Consume the message and call the stock service. [todo 5] - Verify that the operation wasn't already process to keep an idempotent process. [todo 6] - Notify by calling the right method to acknowledge the changes on stock. [todo 7] - Notify by sending a message to kafka that stock could NOT be modified. [todo 8] - Save the operation as processed so it won't be process several times. [todo 9] - Notify by sending a message to kafka that stock was modified successfully. Checklist 1. Verify that you sent a kafka message You can verify the creation of your messages by creating a consumer via command line on your docker. To do so, you need to run the following command: docker exec $(docker ps | awk '$2 == \"wurstmeister/kafka:1.0.0\"' | awk '{print $1}') kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STOCK --from-beginning You should see the messages you sent for acknowledgement and stock's modification.","title":"5.2 - Stock"},{"location":"user-guide/stock/#53-monolith","text":"[todo 10] - Depending on the message sent by Stock for acknowledgement, set the status for the order ( PAYED or CANCEL ) [todo 11] - In case of success, update the stats and notify the stats microservice.","title":"5.3 - Monolith"},{"location":"user-guide/stock/#list-of-todos","text":"Todo File(s) 1 com.homics.monolith.model.Article 2 com.homics.monolith.service.OrderService 3 com.homics.monolith.service.StockService 4 com.homics.stock.service.ImpactStockConsumer 5 com.homics.stock.service.StockService 6 com.homics.stock.service.StockService 7 com.homics.stock.service.StockService 8 com.homics.stock.service.StockService 9 com.homics.stock.service.StockAcknowledgmentProducer 10 com.homics.stock.service.OrderService 11 com.homics.monolith.service.OrderService","title":"List of TODOs"},{"location":"user-guide/stock/#good-to-know","text":"When working with kafka, we can set the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. We are working with the first choice. It constrains us to have idempotent messages. Idempotent means that an action always gives the same result even if you played several times. In our case, the same message can be read multiple times and will give the same result. For example, in the stats microservice, the second message only updates the data since the orderId is unique. It explains why we keep the table StockOperation .","title":"Good to know"},{"location":"user-guide/stock/#whats-next-exercise-6-containers","text":"Let's deploy our market place in containers.","title":"What's next ? Exercise 6: Containers"},{"location":"user-guide/user-activity/","text":"Exercise 1: Our First \u03bc-service: User Activity Previously on HOMicS -> Exercise 0: Monolith Context In our application, we track user activity upon login and logout. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomAuthenticationSuccessHandler and CustomLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler in the official documentation . The front fetches those events for display through an internal API in UserActivityInternalController . Goal We are going to create a new service in charge of logging user activities. Let's be creative and call it: 'user-activity'. It will store every user activities in its own database and display the information on a dedicated page. The monolith will call this microservice via API to notify of a successful user login or logout. At your keyboards Checkout the branch: git checkout exercise-1 There is a new folder for the user-activity microservice. You are not going to start from scratch but you will need to implement some of the API. 1.1 - User Activity [todo 1] - Save a user's activity In UserActivityApiController , register any activity sent via the new API /user/api/activity . You will need to use the @PostMapping with the @RequestBody annotations to extract the right DTO. The @RequestMapping annotation on the class already specifies the URI /user/api . Checklist : Run the user-activity project with the following command to access the microservice via localhost:8080/user/userActivity : mvn spring-boot:run -pl user-activity You should see your microservice up. The User Activity micro tab works but any other tab returns a 404. It's logic since the monolith is the one providing those pages but it isn't up. Call the api with the following command to log an activity: curl -d '{\"username\":\"Jean Bonbeurre\", \"activityType\":\"LOGIN\", \"activityDate\":\"2019-04-18T15:00:00.000Z\"}' -H \"content-type: application/json\" http://localhost:8080/user/api/activity Check on the localhost:8080/user/userActivity that you can see the new activity that you just sent. [todo 2] - Start the monolith mvn spring-boot:run -pl monolith You realize that you have the following error: 2019-12-25 23:20:56.600 ERROR 10837 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured. Action: Verify the connector's configuration, identify and stop any process that's listening on port 8080, or configure this application to listen on another port. The reason is that the two services are started on the same port. Let's change the port for user-activity. Open the file application.yaml and complete the TODO 1.1.2 to change the server port to 9001 Checklist : Restart your two apps : # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Log in on to the app localhost:8080/mono/login and go to User Activity micro tab. You can see the table for the user activities but it's empty. Weird right, since you just logged in. How does the monolith 'talk' with the User microservice? 1.2 - Monolith [todo 3] - In the monolith app, in the UserActivityService class, edit the post() method to call the microservice using restTemplate . [todo 4] - Modify the UserActivityService methods addLogin() and addLogout() to send data to the new microservice, using the new post() method. Checklist : Restart your two apps: # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Log on the monolith . Navigate to the User Activity Micro tab and you should see the same table than before with your activities. [todo 5] - Clean up As a final step, remove any code related to the user activity in the monolith. We took care of the front for you. Great, you just created your first microservice and connected it to your monolith. Not too bad. List of TODOs locations Todo File(s) 1 com.homics.useractivity.controller.UserActivityApiController 2 application.yaml for user-activity 3 com.homics.monolith.service.UserActivityService 4 com.homics.monolith.service.UserActivityService 5 com.homics.monolith.service.UserActivityService / com.homics.monolith.model.UserActivity / com.homics.monolith.controller.UserActivityInternalController Database You can access the database console via the following url . Results You should see the following screen. Did you notice the port number after 'localhost' in the URL? Did you realize that you can access the User Activity microservice on port 9001 without authentication? The user navigating on the application can see that we are switching between two ports/applications. We did not copy the authentication on the new microservice, but we could. Let's see in the next exercise how to centralize the authentication and to have a single entry point in our application. What's next ? Exercise 2: Gateway","title":"exercise 1 - User Activity"},{"location":"user-guide/user-activity/#exercise-1-our-first-service-user-activity","text":"Previously on HOMicS -> Exercise 0: Monolith","title":"Exercise 1: Our First \u03bc-service: User Activity"},{"location":"user-guide/user-activity/#context","text":"In our application, we track user activity upon login and logout. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomAuthenticationSuccessHandler and CustomLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler in the official documentation . The front fetches those events for display through an internal API in UserActivityInternalController .","title":"Context"},{"location":"user-guide/user-activity/#goal","text":"We are going to create a new service in charge of logging user activities. Let's be creative and call it: 'user-activity'. It will store every user activities in its own database and display the information on a dedicated page. The monolith will call this microservice via API to notify of a successful user login or logout.","title":"Goal"},{"location":"user-guide/user-activity/#at-your-keyboards","text":"Checkout the branch: git checkout exercise-1 There is a new folder for the user-activity microservice. You are not going to start from scratch but you will need to implement some of the API.","title":"At your keyboards"},{"location":"user-guide/user-activity/#11-user-activity","text":"[todo 1] - Save a user's activity In UserActivityApiController , register any activity sent via the new API /user/api/activity . You will need to use the @PostMapping with the @RequestBody annotations to extract the right DTO. The @RequestMapping annotation on the class already specifies the URI /user/api . Checklist : Run the user-activity project with the following command to access the microservice via localhost:8080/user/userActivity : mvn spring-boot:run -pl user-activity You should see your microservice up. The User Activity micro tab works but any other tab returns a 404. It's logic since the monolith is the one providing those pages but it isn't up. Call the api with the following command to log an activity: curl -d '{\"username\":\"Jean Bonbeurre\", \"activityType\":\"LOGIN\", \"activityDate\":\"2019-04-18T15:00:00.000Z\"}' -H \"content-type: application/json\" http://localhost:8080/user/api/activity Check on the localhost:8080/user/userActivity that you can see the new activity that you just sent. [todo 2] - Start the monolith mvn spring-boot:run -pl monolith You realize that you have the following error: 2019-12-25 23:20:56.600 ERROR 10837 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured. Action: Verify the connector's configuration, identify and stop any process that's listening on port 8080, or configure this application to listen on another port. The reason is that the two services are started on the same port. Let's change the port for user-activity. Open the file application.yaml and complete the TODO 1.1.2 to change the server port to 9001 Checklist : Restart your two apps : # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Log in on to the app localhost:8080/mono/login and go to User Activity micro tab. You can see the table for the user activities but it's empty. Weird right, since you just logged in. How does the monolith 'talk' with the User microservice?","title":"1.1 - User Activity"},{"location":"user-guide/user-activity/#12-monolith","text":"[todo 3] - In the monolith app, in the UserActivityService class, edit the post() method to call the microservice using restTemplate . [todo 4] - Modify the UserActivityService methods addLogin() and addLogout() to send data to the new microservice, using the new post() method. Checklist : Restart your two apps: # monolith mvn spring-boot:run -pl monolith # user-activity mvn spring-boot:run -pl user-activity Log on the monolith . Navigate to the User Activity Micro tab and you should see the same table than before with your activities. [todo 5] - Clean up As a final step, remove any code related to the user activity in the monolith. We took care of the front for you. Great, you just created your first microservice and connected it to your monolith. Not too bad.","title":"1.2 - Monolith"},{"location":"user-guide/user-activity/#list-of-todos-locations","text":"Todo File(s) 1 com.homics.useractivity.controller.UserActivityApiController 2 application.yaml for user-activity 3 com.homics.monolith.service.UserActivityService 4 com.homics.monolith.service.UserActivityService 5 com.homics.monolith.service.UserActivityService / com.homics.monolith.model.UserActivity / com.homics.monolith.controller.UserActivityInternalController","title":"List of TODOs locations"},{"location":"user-guide/user-activity/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/user-activity/#results","text":"You should see the following screen. Did you notice the port number after 'localhost' in the URL? Did you realize that you can access the User Activity microservice on port 9001 without authentication? The user navigating on the application can see that we are switching between two ports/applications. We did not copy the authentication on the new microservice, but we could. Let's see in the next exercise how to centralize the authentication and to have a single entry point in our application.","title":"Results"},{"location":"user-guide/user-activity/#whats-next-exercise-2-gateway","text":"","title":"What's next ? Exercise 2: Gateway"}]}