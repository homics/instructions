{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to L'Atelier des Chefs: du monolith aux micro-services Homics -> Hands On Micro Service Subject Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices. Presentation Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github . What does microservice mean? Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey? Why microservice? It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Home"},{"location":"#welcome-to-latelier-des-chefs-du-monolith-aux-micro-services","text":"Homics -> Hands On Micro Service","title":"Welcome to L'Atelier des Chefs: du monolith aux micro-services"},{"location":"#subject","text":"Ingredient: A fucking big monolith A heterogeneous stress on the application An exponential entropy The usual recipe : Take the way pasted monolith Cut it equally in height parts Heat it at 200 transactions per seconds Remove your performant microservices from the oven In a kitchen, this recipe seems pretty simple. In our developer world, we learn pretty fast that it's not usually the case. When do you split a monolith? How do you extract relevant functionality? What are the difficulties we are going to encounter? How do the microservices communicate? There isn't one recipe to split a monolith. This HandsOn will introduce our discovery and experience on the matter. Join us on this journey to migrate a MarketPlace monolith into microservices.","title":"Subject"},{"location":"#presentation","text":"Mirakl , the leading provider of Marketplace Solutions, started the migration of their huge application toward microservices. Those last few years, the different teams have been facing a lot of problems. After some reflexion on this adventure, we realized that it's important to clarify this important and amazing process. On one hand, we have learned at our expenses that microservices are not the solution for all the problems. On the other hand, they are very interesting in the evolution of an application. The goal of this HandsOn is to retrace our story through different exercises. The class will treat of the following subjects: How do you split a monolith How do you communicate between microservices ? (HTTP, events, etc ...) Transaction with microservices Resilience in micro-service (peak load, network latency, outage ...) This HandsOn is the work of three developers: Nicolas Favier @Takima Eric Ndouakulu Kiaku Mbuta @Mirakl Benjamin Yvernault @Takima You can find all the code on Homics Github .","title":"Presentation"},{"location":"#what-does-microservice-mean","text":"Microservice is an architectural style in application development where you decide to separate your application into a set of loosely couple services. It's a difficult process with a lot of questions you need to ask yourself. But why does someone decide to start this journey?","title":"What does microservice mean?"},{"location":"#why-microservice","text":"It's a long trip to extract microservices from your monolith. You will need to migrate a lot of your architecture and create new pipelines for your CI but there are a lot of benefits of doing this: Highly maintainable and testable Loosely coupled Independently deployable Organized around business capabilities What those points mean is that it makes the application easier to understand, develop, test, and become more resilient to architecture erosion. The management of your service can be done by a single team that does not need to know the application as a whole. It also enables an organization to evolve its technology stack.","title":"Why microservice?"},{"location":"about/","text":"About us Speakers Nicolas Favier Eric Ndouakulu Kiaku Mbuta Benjamin Yvernault Benjamin recently left the world of data for the applications Web univers. He joined Takima beginning 2018. Takima is a consulting company specialised in fullstack development, DevOps, or Big Data. Since October 2018, he works at Mirakl, the leading provider of Marketplace Solutions. He joined one of the team developing the core system of the monolith. Takima & Mirakl at the Paris DevoxX 2019: Come see us in person","title":"About"},{"location":"about/#about-us","text":"","title":"About us"},{"location":"about/#speakers","text":"","title":"Speakers"},{"location":"about/#nicolas-favier","text":"","title":"Nicolas Favier"},{"location":"about/#eric-ndouakulu-kiaku-mbuta","text":"","title":"Eric Ndouakulu Kiaku Mbuta"},{"location":"about/#benjamin-yvernault","text":"Benjamin recently left the world of data for the applications Web univers. He joined Takima beginning 2018. Takima is a consulting company specialised in fullstack development, DevOps, or Big Data. Since October 2018, he works at Mirakl, the leading provider of Marketplace Solutions. He joined one of the team developing the core system of the monolith.","title":"Benjamin Yvernault"},{"location":"about/#takima-mirakl-at-the-paris-devoxx-2019-come-see-us-in-person","text":"","title":"Takima &amp; Mirakl at the Paris DevoxX 2019: Come see us in person"},{"location":"setup/","text":"Setup to follow the HOMicS Github All the code for this HandsOn is hosted on github under the homics project. Java & Maven The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here . React & Node The front has been implemented in React . You don't need to play with it. You can find it in each frontend folders. We added a plugin in maven to build it with your backend application and both will be present on the same port. You need to install node . Docker & Docker-compose We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here . curl command You can set it up on windows via this link . It's available on macOs and Linux by default.","title":"Setup"},{"location":"setup/#setup-to-follow-the-homics","text":"","title":"Setup to follow the HOMicS"},{"location":"setup/#github","text":"All the code for this HandsOn is hosted on github under the homics project.","title":"Github"},{"location":"setup/#java-maven","text":"The back has been developed in Java using maven as software project management. We are using java 8 . You can install it via this instructions . For Maven , it's here .","title":"Java &amp; Maven"},{"location":"setup/#react-node","text":"The front has been implemented in React . You don't need to play with it. You can find it in each frontend folders. We added a plugin in maven to build it with your backend application and both will be present on the same port. You need to install node .","title":"React &amp; Node"},{"location":"setup/#docker-docker-compose","text":"We are using docker starting at step 4 when you will be using kafka. Please install it. for Linux, on this link , select your OS. You can find that information via this command cat /etc/*release for MacOs, follow this link for Windows, follow this link For Docker-compose , it's here .","title":"Docker &amp; Docker-compose"},{"location":"setup/#curl-command","text":"You can set it up on windows via this link . It's available on macOs and Linux by default.","title":"curl command"},{"location":"user-guide/gateway/","text":"Exercise 2 : Gateway Previously on HOMicS -> Exercise 1: User Activity Context In the previous schema, you might realize that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice ? You can go directly to user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But imagine if we have 20 microservices, it's going to be a mess if we need to add the security in each of them. The services won't be loosely coupled. It's where the gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway. Goal Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice. Everything has been implemented in other microservices. You only need to edit the gateway. At your keyboard Checkout the branch: git checkout exercise-2 There is a new folder for the gateway microservice. You are not going to start from scratch but you will need to implement some part of it. Start the gateway: mvn spring-boot:run -pl gateway Navigate on the different pages and you realize that all pages return a 404. There is no routing in our application. Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix that is an edge service that provides dynamic routing, monitoring, resiliency, security, and more. Spring integrated it in Spring Cloud . <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-netflix-zuul --> <dependency> <groupId>org.springframework.cloud</groupId> <artifactId>spring-cloud-starter-netflix-zuul</artifactId> <version>2.1.1.RELEASE</version> </dependency> You will need to set it up in your application.yaml . zuul documentation is available here Enable Zuul Checkout the second TODO to enable the Zuul Routing. Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Since the Gateway is running on port 8080, the port for the monolith has been changed to 8090. Monolith database You can access the monolith database console via the following url . Verification To verify that gateway is well implemented, launch all the applications: # Run monolith project mvn spring-boot:run -pl monolith # Run user-activity project mvn spring-boot:run -pl user-activity # Run Gateway project mvn spring-boot:run -pl gateway Access the HOMicS MarketPlace . You should be on the gateway. After logging, you should be directly redirect to the monolith and you can notify that the port is still 8080. You should be able to access as well the user-activity microservice on the User Activity micro tab. You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done. Let's continue on to the next step. What's next ? Exercise 3: Stats","title":"exercise 2 - Gateway"},{"location":"user-guide/gateway/#exercise-2-gateway","text":"Previously on HOMicS -> Exercise 1: User Activity","title":"Exercise 2 : Gateway"},{"location":"user-guide/gateway/#context","text":"In the previous schema, you might realize that there is a flaw. We don't have any authentication for the micro-service. What happens if you connect directly to the user-activity microservice ? You can go directly to user-activity . The login page is skipped and the data is accessible! Oopsy, not great at all. We could duplicate all the security code in the new microservice. But imagine if we have 20 microservices, it's going to be a mess if we need to add the security in each of them. The services won't be loosely coupled. It's where the gateway becomes handy. A gateway is a service that provides a single-entry point for certain groups of microservices. Any requests to our application will go through the gateway.","title":"Context"},{"location":"user-guide/gateway/#goal","text":"Create the Gateway microservice responsible for all authentication and redirection. It's going to handle the authentication and redirect to the monolith or the user-activity microservice. Everything has been implemented in other microservices. You only need to edit the gateway.","title":"Goal"},{"location":"user-guide/gateway/#at-your-keyboard","text":"Checkout the branch: git checkout exercise-2 There is a new folder for the gateway microservice. You are not going to start from scratch but you will need to implement some part of it. Start the gateway: mvn spring-boot:run -pl gateway Navigate on the different pages and you realize that all pages return a 404. There is no routing in our application. Application.yaml There won't be any database for the gateway since it's not holding any data. It's going to be running on port 8080. We are using ZUUL developed by Netflix that is an edge service that provides dynamic routing, monitoring, resiliency, security, and more. Spring integrated it in Spring Cloud . <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-netflix-zuul --> <dependency> <groupId>org.springframework.cloud</groupId> <artifactId>spring-cloud-starter-netflix-zuul</artifactId> <version>2.1.1.RELEASE</version> </dependency> You will need to set it up in your application.yaml . zuul documentation is available here Enable Zuul Checkout the second TODO to enable the Zuul Routing. Logged user information Last but not least, you need to add the logged user to the headers so all micro services will be able to retrieve the connected user. Open AddUserFilter and implement the run method so it adds the username into the request context. Since the Gateway is running on port 8080, the port for the monolith has been changed to 8090.","title":"At your keyboard"},{"location":"user-guide/gateway/#monolith-database","text":"You can access the monolith database console via the following url .","title":"Monolith database"},{"location":"user-guide/gateway/#verification","text":"To verify that gateway is well implemented, launch all the applications: # Run monolith project mvn spring-boot:run -pl monolith # Run user-activity project mvn spring-boot:run -pl user-activity # Run Gateway project mvn spring-boot:run -pl gateway Access the HOMicS MarketPlace . You should be on the gateway. After logging, you should be directly redirect to the monolith and you can notify that the port is still 8080. You should be able to access as well the user-activity microservice on the User Activity micro tab. You can still access the other services directly on each port 8090 and 9001. In practice, you will block those ports from the outside via a firewall. Well done. Let's continue on to the next step.","title":"Verification"},{"location":"user-guide/gateway/#whats-next-exercise-3-stats","text":"","title":"What's next ? Exercise 3: Stats"},{"location":"user-guide/kafka/","text":"Exercise 4 : Stats with Kafka Previously on HOMicS -> Exercise 3: Stats Context Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable. A word on KAFKA Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages. Goal We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which will consume the message. Setup Install Docker et Docker-compose For this exercise we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. Clone the common-messaging project : git clone https://github.com/homics/commons-messaging.git This repository contains the kafka configuration for our project with the docker-compose file to launch it. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd /tools/docker/kafka/ docker compose up To stop docker compose stop At your keyboard Add the common-messaging dependency to each project poms ( monolith and stats ): <!--All dependencies for kafka and messaging--> <dependency> <groupId>com.homics.commons-messaging</groupId> <artifactId>commons-messaging</artifactId> <version>1.0.0</version> </dependency> Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = \"statsMessageFactory\") public void onImpactStockMessage(@Payload OrderPayedMessage impactStockMessage) { ... } Save this message into the database Back to the monolith, remove StatsTask and OrderStat table and the related code. Verification To verify that stats with kafka is well implemented, - launch the monolith - pass some orders - start the microservice stats - verify that the stats are present and computed. What's next ? Exercise 5: Stock","title":"exercise 4 - Stats with Kafka"},{"location":"user-guide/kafka/#exercise-4-stats-with-kafka","text":"Previously on HOMicS -> Exercise 3: Stats","title":"Exercise 4 : Stats with Kafka"},{"location":"user-guide/kafka/#context","text":"Do you remember what we said at the beginning about getting the monolith thinner? The previous solution has a considerable drawback. We had to add logic in the monolith and it's not really scalable.","title":"Context"},{"location":"user-guide/kafka/#a-word-on-kafka","text":"Apache Kafka is an event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue by LinkedIn, Kafka is based on an abstraction of a distributed commit log. The main advantages of kafka are : High-throughput Low Latency Fault-Tolerant Scalability Distributed Keep in mind, adding kafka comes with a cost. It's a library with a learning curve and advance concepts. We are using Kafka to produce, consume and store messages.","title":"A word on KAFKA"},{"location":"user-guide/kafka/#goal","text":"We will change the exercise 3 but this time using kafka. No need for table and crawler anymore. When an order is payed, an event is sent. Kafka stores it until a consumer reads it. It's very convenient: our monolith doesn't have to battle with acknowledgment anymore. It's the stats microservice which will consume the message.","title":"Goal"},{"location":"user-guide/kafka/#setup","text":"Install Docker et Docker-compose For this exercise we need to have a running instance of kafka. The easiest way is to launch it via docker. We can then easily restart or reset it. You will find a docker-compose file already present. So first of all, download docker and start docker. Go back to the Setup page if needed. Clone the common-messaging project : git clone https://github.com/homics/commons-messaging.git This repository contains the kafka configuration for our project with the docker-compose file to launch it. We are using Spring for Apache Kafka. All the configuration for serializing, topic creation is done in the common-messaging lib. Run kafka In /tools/docker/kafka/ , the docker-compose file will launch an instance of zookeeper and kafka . To start kafka simply run : cd /tools/docker/kafka/ docker compose up To stop docker compose stop","title":"Setup"},{"location":"user-guide/kafka/#at-your-keyboard","text":"Add the common-messaging dependency to each project poms ( monolith and stats ): <!--All dependencies for kafka and messaging--> <dependency> <groupId>com.homics.commons-messaging</groupId> <artifactId>commons-messaging</artifactId> <version>1.0.0</version> </dependency> Send a kafka message Switch the API calls in the monolith to send an OrderPayedMessages message to kafka. To send a message with kafka : private KafkaTemplate<String, OrderPayedMessage> kafkaTemplate; Message<OrderPayedMessage> message = MessageBuilder .withPayload(new OrderPayedMessage(1,1,\"user\")) .setHeader(KafkaHeaders.TOPIC, TOPIC_STATS) .build(); kafkaTemplate.send(message); In the microservice, retrieve the message with kafka : @KafkaListener(topics = TOPIC_STATS, groupId = GROUP_ID, containerFactory = \"statsMessageFactory\") public void onImpactStockMessage(@Payload OrderPayedMessage impactStockMessage) { ... } Save this message into the database Back to the monolith, remove StatsTask and OrderStat table and the related code.","title":"At your keyboard"},{"location":"user-guide/kafka/#verification","text":"To verify that stats with kafka is well implemented, - launch the monolith - pass some orders - start the microservice stats - verify that the stats are present and computed.","title":"Verification"},{"location":"user-guide/kafka/#whats-next-exercise-5-stock","text":"","title":"What's next ? Exercise 5: Stock"},{"location":"user-guide/monolith/","text":"Exercise 0 : The Monolith Fruit Market Place Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users. Architecture The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back. Keep in mind that you will need to recompile the front everytime you fetch a new exercise via the following command but no worries, we will put some reminders: mvn clean install Steps: Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/handson.git Build your project: mvn clean install This will compute your front and back into a single application. Start your application (if you are using an IDE such as IntelliJ, you can run the application through it) : mvn spring-boot:run -pl monolith Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin . What's next ? Exercise 1: User Activity","title":"exercise 0 - Monolith"},{"location":"user-guide/monolith/#exercise-0-the-monolith","text":"","title":"Exercise 0 : The Monolith"},{"location":"user-guide/monolith/#fruit-market-place","text":"Our application is a fruit market place. You can select any items from a list of ten fruits and put them in your cart. You can access your cart and pay for your order. Some stats are computed to let you know what is the average prize of your cart. We implemented a tracking service for your user: we are saving the login and logout action of any users.","title":"Fruit Market Place"},{"location":"user-guide/monolith/#architecture","text":"The monolith is pretty simple. We want to avoid any confusion with a complicated application. The schema below explains the monolith architecture and what composed it. The application is using SpringBoot with Spring Data JPA and Spring Security for the back. The database is a h2 and the front is implemented in React . You won't need to interact with the front. It's already implemented for each exercise in this HandsOn. You will only play with the back. Keep in mind that you will need to recompile the front everytime you fetch a new exercise via the following command but no worries, we will put some reminders: mvn clean install","title":"Architecture"},{"location":"user-guide/monolith/#steps","text":"Start the monolith To run your monolith, clone the repository via the following command: git clone https://github.com/homics/handson.git Build your project: mvn clean install This will compute your front and back into a single application. Start your application (if you are using an IDE such as IntelliJ, you can run the application through it) : mvn spring-boot:run -pl monolith Access the application Go to localhost:8080 and log with admin/admin . You should be able to navigate on the application: To access the h2 console, after logging as admin, go to : localhost:8080/console and use the credentials: admin/admin .","title":"Steps:"},{"location":"user-guide/monolith/#whats-next-exercise-1-user-activity","text":"","title":"What's next ? Exercise 1: User Activity"},{"location":"user-guide/stats/","text":"Exercise 3 : Stats Previously on HOMicS -> Exercise 2: Gateway Context In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it. Goal The monolith will save all the stats in a new table. Those stats will be hosted on a new microservice called stats . A schedule task fetch this table and send its content to the microservice. In case of error such as the downtime of the micro-service, the stats will be sent again at the next iteration. We are providing the microservice directly on github. You don't need to edit it. In terms of architecture: At your keyboard Setup Clone the stat repository. git clone https://github.com/homics/stats.git On the monolith checkout exo3-stat git checkout exo3-stat Complete the StatsTask : Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) Fill all TODOs in StatsService: The addOrderStat() saves the orderStat in H2. The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already worked with this template in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, create a class OrderPayedDto, it should match the one in stats microservice. A response status is HttpStatus.OK means the microservice received the information. Then, we remove it from the database. Clean the stats implementation that is not required anymore in the monolith. Database You can access the database console via the following url . Verification To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run monolith project monolith$ mvn spring-boot:run # Run gateway project gateway$ mvn spring-boot:run Access and login to the monolith . Execute two carts and pay them. The stats microservice isn't up and running at that point. Start the microservice: # Run stats project stats$ mvn spring-boot:run Navigate to the Stats Micro tab and you should see the same table than before with the stats from the previous two orders. All the stats should be retrieved. What's next ? Exercise 4: Stats with Kafka","title":"exercise 3 - Stats"},{"location":"user-guide/stats/#exercise-3-stats","text":"Previously on HOMicS -> Exercise 2: Gateway","title":"Exercise 3 : Stats"},{"location":"user-guide/stats/#context","text":"In real life, the stats take some time to compute and do not impact the payment workflow. We are going to extract it into a microservice. What happens if the microservice is down ? All data sent during the down time will be lost. A simple way to fix this issue is to work with acknowledgment. Let's implement it.","title":"Context"},{"location":"user-guide/stats/#goal","text":"The monolith will save all the stats in a new table. Those stats will be hosted on a new microservice called stats . A schedule task fetch this table and send its content to the microservice. In case of error such as the downtime of the micro-service, the stats will be sent again at the next iteration. We are providing the microservice directly on github. You don't need to edit it. In terms of architecture:","title":"Goal"},{"location":"user-guide/stats/#at-your-keyboard","text":"Setup Clone the stat repository. git clone https://github.com/homics/stats.git On the monolith checkout exo3-stat git checkout exo3-stat Complete the StatsTask : Every 10 seconds, the statsService should send the stats. You can use the following annotation: @Scheduled(fixedRate = 10000) Fill all TODOs in StatsService: The addOrderStat() saves the orderStat in H2. The sendStats() fetches all orderStats in database, then sends them to the microservice using the restTemplate . You already worked with this template in exercise 1. If you are lost, check it out again. This request will be a POST action on the API : http://localhost:9002/stats/api/orders For the payload, create a class OrderPayedDto, it should match the one in stats microservice. A response status is HttpStatus.OK means the microservice received the information. Then, we remove it from the database. Clean the stats implementation that is not required anymore in the monolith.","title":"At your keyboard"},{"location":"user-guide/stats/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/stats/#verification","text":"To verify that stats is well implemented, launch the gateway, and the monolith applications: # Run monolith project monolith$ mvn spring-boot:run # Run gateway project gateway$ mvn spring-boot:run Access and login to the monolith . Execute two carts and pay them. The stats microservice isn't up and running at that point. Start the microservice: # Run stats project stats$ mvn spring-boot:run Navigate to the Stats Micro tab and you should see the same table than before with the stats from the previous two orders. All the stats should be retrieved.","title":"Verification"},{"location":"user-guide/stats/#whats-next-exercise-4-stats-with-kafka","text":"","title":"What's next ? Exercise 4: Stats with Kafka"},{"location":"user-guide/stock/","text":"Exercise 5 : Stock Previously on HOMicS -> Exercise 4: Stats with Kafka Context Often when splitting microservice, the question of transactions arises. Let's try to discover why through the extraction of the stock microservice. About the stock micro-service Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article. The existing Before the migration when we pay an order, we were executing the following steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction Extract it into a microservice If we extract the stock service in a microservice like we did before, the steps become : Open transaction Ask the micro service to impact the stock Wait for the response Update the order status Close the transaction With this plan, you can see in step 3 that the monolith is waiting for the microservice response. It's pretty bad! Imagine that the call to impact stock times out... Your payment method is going to wait the whole time and so is your user. We need to change to asynchronous. Going async Open transaction Ask the micro service to impact the stock Close the transaction Then, we listen to the microservice event. The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction What happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled. Goal Extract the stock micro service using kafka. The workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verifies and then impacts the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consumes the message and change the order status accordingly At your keyboard Remove the stock column in the monolith Implement the payment workflow previously describe in OrderService . (Topics and messages are already setup in the common-messaging lib) Implement the payment workflow on the micro service side in StockController Good to know When working with kafka, we can set the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. We are working with the first choice. It constrains us to have idempotent messages. Idempotent means that an action always gives the same result even if you played several times. In our case, the same message can be read multiple times and will give the same result. For example, in the stats microservice, the second message only updates the data since the orderId is unique. It explains why we keep the table StockOperation . What's next ? Come see us at our stand and let us know what you though about the Hands On. Please your feedback means a lot to us. If you have 5 mins to spare, could you fill this survey Thank you.","title":"exercise 5 - Stock"},{"location":"user-guide/stock/#exercise-5-stock","text":"Previously on HOMicS -> Exercise 4: Stats with Kafka","title":"Exercise 5 : Stock"},{"location":"user-guide/stock/#context","text":"Often when splitting microservice, the question of transactions arises. Let's try to discover why through the extraction of the stock microservice.","title":"Context"},{"location":"user-guide/stock/#about-the-stock-micro-service","text":"Stock modifications are often spread around a marketplace application. It could be modified from cart, refunds, or inventory. The stock microservice will store and update the stock for each article.","title":"About the stock micro-service"},{"location":"user-guide/stock/#the-existing","text":"Before the migration when we pay an order, we were executing the following steps: Open transaction Check the stock Impact the stock Update the order status Close the transaction","title":"The existing"},{"location":"user-guide/stock/#extract-it-into-a-microservice","text":"If we extract the stock service in a microservice like we did before, the steps become : Open transaction Ask the micro service to impact the stock Wait for the response Update the order status Close the transaction With this plan, you can see in step 3 that the monolith is waiting for the microservice response. It's pretty bad! Imagine that the call to impact stock times out... Your payment method is going to wait the whole time and so is your user. We need to change to asynchronous.","title":"Extract it into a microservice"},{"location":"user-guide/stock/#going-async","text":"Open transaction Ask the micro service to impact the stock Close the transaction Then, we listen to the microservice event. The microservice call the monolith when the stock is impacted Open transaction Update the order status Close the transaction What happens if the result of the microservice is \"not enough stock\" ? We save the order as cancelled.","title":"Going async"},{"location":"user-guide/stock/#goal","text":"Extract the stock micro service using kafka. The workflow becomes: An ImpactStockMessage is send to kafka The stock micro-service verifies and then impacts the article stock A StockAcknowledgmentMessage is send with a status succeed or not The monolith consumes the message and change the order status accordingly","title":"Goal"},{"location":"user-guide/stock/#at-your-keyboard","text":"Remove the stock column in the monolith Implement the payment workflow previously describe in OrderService . (Topics and messages are already setup in the common-messaging lib) Implement the payment workflow on the micro service side in StockController","title":"At your keyboard"},{"location":"user-guide/stock/#good-to-know","text":"When working with kafka, we can set the configuration to have either: All messages received but with possible duplicates. No duplicate but you can miss some messages. We are working with the first choice. It constrains us to have idempotent messages. Idempotent means that an action always gives the same result even if you played several times. In our case, the same message can be read multiple times and will give the same result. For example, in the stats microservice, the second message only updates the data since the orderId is unique. It explains why we keep the table StockOperation .","title":"Good to know"},{"location":"user-guide/stock/#whats-next","text":"Come see us at our stand and let us know what you though about the Hands On. Please your feedback means a lot to us. If you have 5 mins to spare, could you fill this survey Thank you.","title":"What's next ?"},{"location":"user-guide/user-activity/","text":"Exercise 1 : User Activity Previously on HOMicS -> Exercise 0: Monolith Context In our application, we track user activity on log in and log out. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomAuthenticationSuccessHandler and CustomLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler documentation here The front fetches those events for display through an internal API in UserActivityInternalController . Goal We are going to create a new service in charge of user activities. Let's be inventive and call it: user-activity. It will store every user activities in its own database and display the information on a dedicated page. The monolith will call this micro-service via API to notify on a success login or success logout. At your keyboard 1.1 - User microservice: Checkout the branch: git checkout exercise-1 There is a new folder for the user-activity microservice. You are not going to start from scratch but you will need to implement some of the API. In your favorite IDE, open the file UserActivityApiController to complete the first TODO You need to register any activity send via the new API /user/api/activity . You will need to use @PostMapping with @RequestBody to extract the right DTO. The @RequestMapping already specified the /user/api Run the user-activity project via the following command to access the microservice via localhost:8080/user/userActivity : mvn spring-boot:run -pl user-activity You should see your microservice up. The User Activity micro tab works but any other tabs return a 404. It's logic since the monolith is the one providing those pages but it isn't up. Call the api via the following command to set an activity: curl -d '{\"username\":\"admin\", \"activityType\":\"LOGIN\", \"activityDate\":\"2019-04-18T15:00:00.000Z\"}' -H \"content-type: application/json\" -X POST http://localhost:9001/user/api/activity Start the monolith: mvn spring-boot:run -pl monolith You realize that you have an error like the following : 2019-03-31 18:20:56.600 ERROR 10837 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured. Action: Verify the connector's configuration, identify and stop any process that's listening on port 8080, or configure this application to listen on another port. Since the two services are started on the same port, it makes sense. Let's change the port for user-activity Open the file application.yaml and complete the TODO 1.1.4 to change the server port to 9001 Restart your app and everything is in order except that login and logout from the monolith doesn't add anything to your microservice. Oo How does the monolith discuss with the User microservice? 1.2 - Connect the monolith: Complete the first TODO by editing the post() method to execute a restTemplate call. Change the two methods called by the monolith to send the data. Clean monolith: As a final step, you will clean the monolith to remove any code related to the user activity. We took care of the front for you. Follow the 1.2.3 TODO . Great, you just created your first microservice and connected it to your monolith. Not too bad. Database You can access the database console via the following url . Verification To verify that user-activity is well implemented, launch both applications: # Run monolith project mvn spring-boot:run -pl monolith # Run user-activity project mvn spring-boot:run -pl user-activity Access and login to the monolith . Navigate to the User Activity Micro tab and you should see the same table than before. Troubleshooting If you have a 404 error, your front might not be compiled on your microservice. You remember our reminder on compiling it. Let's do it again here and run mvn clean install . What's next ? Exercise 2: Gateway","title":"exercise 1 - User Activity"},{"location":"user-guide/user-activity/#exercise-1-user-activity","text":"Previously on HOMicS -> Exercise 0: Monolith","title":"Exercise 1 : User Activity"},{"location":"user-guide/user-activity/#context","text":"In our application, we track user activity on log in and log out. This functionality is already implemented in the monolith codebase. In WebSecurityConfig , you can find two classes CustomAuthenticationSuccessHandler and CustomLogoutSuccessHandler . Those classes implement some Spring Security interfaces to define a strategy used to handle a successful user authentication or logout. In our case, they call the UserActivityService which save the event in database through it UserActivityRepository . you can read more about spring security AuthenticationSuccessHandler documentation here The front fetches those events for display through an internal API in UserActivityInternalController .","title":"Context"},{"location":"user-guide/user-activity/#goal","text":"We are going to create a new service in charge of user activities. Let's be inventive and call it: user-activity. It will store every user activities in its own database and display the information on a dedicated page. The monolith will call this micro-service via API to notify on a success login or success logout.","title":"Goal"},{"location":"user-guide/user-activity/#at-your-keyboard","text":"","title":"At your keyboard"},{"location":"user-guide/user-activity/#11-user-microservice","text":"Checkout the branch: git checkout exercise-1 There is a new folder for the user-activity microservice. You are not going to start from scratch but you will need to implement some of the API. In your favorite IDE, open the file UserActivityApiController to complete the first TODO You need to register any activity send via the new API /user/api/activity . You will need to use @PostMapping with @RequestBody to extract the right DTO. The @RequestMapping already specified the /user/api Run the user-activity project via the following command to access the microservice via localhost:8080/user/userActivity : mvn spring-boot:run -pl user-activity You should see your microservice up. The User Activity micro tab works but any other tabs return a 404. It's logic since the monolith is the one providing those pages but it isn't up. Call the api via the following command to set an activity: curl -d '{\"username\":\"admin\", \"activityType\":\"LOGIN\", \"activityDate\":\"2019-04-18T15:00:00.000Z\"}' -H \"content-type: application/json\" -X POST http://localhost:9001/user/api/activity Start the monolith: mvn spring-boot:run -pl monolith You realize that you have an error like the following : 2019-03-31 18:20:56.600 ERROR 10837 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured. Action: Verify the connector's configuration, identify and stop any process that's listening on port 8080, or configure this application to listen on another port. Since the two services are started on the same port, it makes sense. Let's change the port for user-activity Open the file application.yaml and complete the TODO 1.1.4 to change the server port to 9001 Restart your app and everything is in order except that login and logout from the monolith doesn't add anything to your microservice. Oo How does the monolith discuss with the User microservice?","title":"1.1 - User microservice:"},{"location":"user-guide/user-activity/#12-connect-the-monolith","text":"Complete the first TODO by editing the post() method to execute a restTemplate call. Change the two methods called by the monolith to send the data. Clean monolith: As a final step, you will clean the monolith to remove any code related to the user activity. We took care of the front for you. Follow the 1.2.3 TODO . Great, you just created your first microservice and connected it to your monolith. Not too bad.","title":"1.2 - Connect the monolith:"},{"location":"user-guide/user-activity/#database","text":"You can access the database console via the following url .","title":"Database"},{"location":"user-guide/user-activity/#verification","text":"To verify that user-activity is well implemented, launch both applications: # Run monolith project mvn spring-boot:run -pl monolith # Run user-activity project mvn spring-boot:run -pl user-activity Access and login to the monolith . Navigate to the User Activity Micro tab and you should see the same table than before.","title":"Verification"},{"location":"user-guide/user-activity/#troubleshooting","text":"If you have a 404 error, your front might not be compiled on your microservice. You remember our reminder on compiling it. Let's do it again here and run mvn clean install .","title":"Troubleshooting"},{"location":"user-guide/user-activity/#whats-next-exercise-2-gateway","text":"","title":"What's next ? Exercise 2: Gateway"}]}